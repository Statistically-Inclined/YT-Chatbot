{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e0aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt-dlp in c:\\users\\user\\desktop\\yt_video_summariser\\venv\\lib\\site-packages (2025.5.22)\n",
      "Collecting webvtt-py\n",
      "  Downloading webvtt_py-0.5.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading webvtt_py-0.5.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: webvtt-py\n",
      "Successfully installed webvtt-py-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U yt-dlp\n",
    "!pip install webvtt-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d2fe76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] EzYaFF7ahKw: nsig extraction failed: Some formats may be missing\n",
      "         n = 3UTmrCgwxKtvMdk ; player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] EzYaFF7ahKw: nsig extraction failed: Some formats may be missing\n",
      "         n = NijEKg1rs9sEojv ; player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] EzYaFF7ahKw: nsig extraction failed: Some formats may be missing\n",
      "         n = MwPk2e18YgvHAFf ; player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] EzYaFF7ahKw: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Transcript file not found.                            \n"
     ]
    }
   ],
   "source": [
    "from yt_dlp import YoutubeDL\n",
    "import os\n",
    "\n",
    "def download_transcript(video_url: str):\n",
    "    options = {\n",
    "        'skip_download': True,\n",
    "        # 'writesubtitles': True,\n",
    "        'writeautomaticsub': True,\n",
    "        'subtitleslangs': ['en'],\n",
    "        'subtitlesformat': 'vtt',\n",
    "        'outtmpl': '%(id)s.%(ext)s',  # filename will be video_id.vtt\n",
    "        'quiet': True,\n",
    "        'writesubtitles': False,\n",
    "        'noplaylist': True,\n",
    "\n",
    "    }\n",
    "\n",
    "    with YoutubeDL(options) as ydl:\n",
    "        info = ydl.extract_info(video_url, download=True)\n",
    "        video_id = info.get(\"id\")\n",
    "        subtitle_file = f\"{video_id}.vtt\"\n",
    "        \n",
    "        if os.path.exists(subtitle_file):\n",
    "            print(f\"‚úÖ Transcript downloaded as {subtitle_file}\")\n",
    "            # Convert VTT to plain text\n",
    "            with open(subtitle_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                lines = f.readlines()\n",
    "            text_lines = [line.strip() for line in lines if not line.startswith(('WEBVTT', '00', '\\n'))]\n",
    "            transcript = \"\\n\".join(text_lines)\n",
    "            print(\"\\nüìù Transcript:\\n\")\n",
    "            print(transcript[:1000])  # Just showing first 1000 characters\n",
    "        else:\n",
    "            print(\"‚ùå Transcript file not found.\")\n",
    "\n",
    "# Example usage\n",
    "download_transcript(\"https://www.youtube.com/watch?v=EzYaFF7ahKw&list=PLKnIA16_RmvaTbihpo4MtzVm4XOQa0ER0&index=19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "033cf88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] Extracting URL: https://www.youtube.com/watch?v=EzYaFF7ahKw&list=PLKnIA16_RmvaTbihpo4MtzVm4XOQa0ER0&index=19\n",
      "[youtube:tab] Downloading just the video EzYaFF7ahKw because of --no-playlist\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=EzYaFF7ahKw\n",
      "[youtube] EzYaFF7ahKw: Downloading webpage\n",
      "[youtube] EzYaFF7ahKw: Downloading tv client config\n",
      "[youtube] EzYaFF7ahKw: Downloading tv player API JSON\n",
      "[youtube] EzYaFF7ahKw: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] EzYaFF7ahKw: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] EzYaFF7ahKw: Downloading player fc2a56a5-main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] EzYaFF7ahKw: nsig extraction failed: Some formats may be missing\n",
      "         n = Upvp0HDSeiB8VLh ; player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] EzYaFF7ahKw: nsig extraction failed: Some formats may be missing\n",
      "         n = DqeT1IRiyG1u5jg ; player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] EzYaFF7ahKw: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] EzYaFF7ahKw: Downloading m3u8 information\n",
      "[info] EzYaFF7ahKw: Downloading subtitles: en\n",
      "[info] EzYaFF7ahKw: Downloading 1 format(s): 620+234-1\n",
      "[info] Writing video subtitles to: Tool Calling in LangChain ÔΩú Generative AI using LangChain ÔΩú Video 17 ÔΩú CampusX.en.vtt\n",
      "[download] Destination: Tool Calling in LangChain ÔΩú Generative AI using LangChain ÔΩú Video 17 ÔΩú CampusX.en.vtt\n",
      "[download] 100% of  404.06KiB in 00:00:01 at 344.20KiB/s\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "video_url = \"https://www.youtube.com/watch?v=EzYaFF7ahKw&list=PLKnIA16_RmvaTbihpo4MtzVm4XOQa0ER0&index=19\"\n",
    "\n",
    "options = {\n",
    "    'skip_download': True,\n",
    "    'writesubtitles': False,\n",
    "    'writeautomaticsub': True,\n",
    "    'subtitleslangs': ['en'],\n",
    "    'subtitlesformat': 'vtt',\n",
    "    'outtmpl': '%(title)s.%(ext)s',\n",
    "    'noplaylist': True\n",
    "}\n",
    "\n",
    "with yt_dlp.YoutubeDL(options) as ydl:\n",
    "    ydl.download([video_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec2c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=zYGDpG-pTho&t=456s\n",
      "[youtube] zYGDpG-pTho: Downloading webpage\n",
      "[youtube] zYGDpG-pTho: Downloading tv client config\n",
      "[youtube] zYGDpG-pTho: Downloading tv player API JSON\n",
      "[youtube] zYGDpG-pTho: Downloading ios player API JSON\n",
      "[youtube] zYGDpG-pTho: Downloading player fc2a56a5-main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] zYGDpG-pTho: nsig extraction failed: Some formats may be missing\n",
      "         n = IpjzjnvKkpRF2PT ; player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] zYGDpG-pTho: nsig extraction failed: Some formats may be missing\n",
      "         n = c6Bo8oI33DZ2zkC ; player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] zYGDpG-pTho: nsig extraction failed: Some formats may be missing\n",
      "         n = x56KFXrFmZBBPdf ; player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] zYGDpG-pTho: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] zYGDpG-pTho: Downloading m3u8 information\n",
      "[info] zYGDpG-pTho: Downloading subtitles: en\n",
      "[info] zYGDpG-pTho: Downloading 1 format(s): 616+234\n",
      "Deleting existing file transcript_temp.en.vtt\n",
      "[info] Writing video subtitles to: transcript_temp.en.vtt\n",
      "[download] Destination: transcript_temp.en.vtt\n",
      "[download] 100% of   90.44KiB in 00:00:00 at 393.15KiB/s\n",
      "['Remember how back in the day people', 'would Google themselves? You type your', 'name into a search engine and you see', 'what it knows about you? Well, the', 'modern equivalent of that is to do the', 'same thing with a chatbot. So, when I', 'ask a large language model, who is', 'Martin Keen? Well, the response varies', \"greatly depending upon which model I'm\", 'asking because different models, they', 'have different training data sets. They', 'have different knowledge cutoff dates.', 'So what a given model knows about me?', 'Well, it differs greatly. But how could', \"we improve the model's answer? Well,\", \"there's three ways. So let's start with\", \"a model here. And we're going to see how\", 'we can improve its responses. Well, the', 'first thing it could do is it could go', 'out and it could perform a search. a', \"search for new data that either wasn't\", 'in its training data set or it was just', 'data that became available after the', 'model finished training. And then it', 'could incorporate those results from the', 'search back into its answer. That is', 'called rag or retrieval augmented', \"generation. That's one method. Or we\", 'could pick a specialized model, a model', \"that's been trained on, let's say,\", 'transcripts of these videos. That would', 'be an example of something called fine', 'tuning. Or we could ask the model a', \"query that better specifies what we're\", 'looking for. So maybe the LLM already', 'knows plenty about the Martin Keen of', \"the world, but let's tell the model that\", \"we're referring to the Martin Keen who\", 'works at IBM rather than the Martin Keen', 'that founded Keen Shoes. That is an', 'example of prompt', 'engineering. Three ways to get better', 'outputs out of large language models,', 'each with their pluses and', \"minuses. Let's start with rag. So, let's\", \"break it down. First, there's retrieval.\", 'So, retrieval of external up-to-ate', \"information. Then, there's augmentation.\", \"That's augmentation of the original\", 'prompt with the retrieved information', \"added in. And then, finally, there's\", \"generation. That's generation of a\", 'response based on all of this enriched', 'context. So, we can think of it like', 'this. So we start with a query and the', 'query comes in to a large language', 'model. Now what rag is going to do is', \"it's first going to go searching through\", 'a corpus of information. So we have this', 'corpus here full of some sort of data.', \"Now perhaps that's your organization's\", 'documents. So it might be spreadsheets,', 'PDFs, internal wiks, you know, stuff', 'like that. But unlike a typical search', 'engine that just matches keywords, Rag', 'converts both your question, the query,', 'and all of the documents into something', 'called', 'vector', 'embeddings. So these are all converted', 'into vectors. essentially turning words', 'and phrases into long lists of numbers', 'that capture their meaning. So when you', \"ask a query like what was our company's\", 'revenue growth last quarter? Well, Rag', 'will find documents that are', 'mathematically similar in meaning to', \"your question, even if they don't use\", 'the exact same words. So it might find', 'documents mentioning fourth quarter', 'performance or quarterly sales. Those', \"don't contain the keyword revenue\", 'growth, but they are semantically', 'similar. Now, once rag finds the', 'relevant information, it adds this', 'information back into your original', 'query before passing it to the language', 'model. So instead of the model just kind', 'of guessing based on its training data,', 'it can now generate a response that', 'incorporates your actual facts and', 'figures. So this makes rag particularly', 'valuable when you are looking for', \"information that is up to date and it's\", 'also very valuable when you need in to', 'add in information that is domain', 'specific as', 'well. But there are some costs to this.', \"Let's go with the red pen. So one cost\", 'that would be the cost of performance', 'for performing all of this because you', 'have this retrieval step here and that', 'adds latency to each query compared to a', 'simple prompt to a model. There are also', 'costs related to just kind of the the', 'processing of this as well. So if we', 'think about what we having to do here,', \"we've got documents that need to be\", 'vector embeddings and we need to store', 'these vector embeddings in a database.', 'All of this adds to processing costs. It', 'adds to infrastructure costs to make', 'this solution work. All right, next up,', 'fine tuning. So remember how we', 'discussed getting better answers about', 'me by training a model specifically on', \"let's say my video transcripts? Well,\", 'that is fine tuning in action. So what', 'we do with fine-tuning is we take a', 'model but specifically an existing model', 'and that existing model has broad', \"knowledge and then we're going to give\", 'it additional specialized training on a', 'focused data set. So this is now', 'specialized to what we want to develop', 'particular expertise on. Now during', \"fine-tuning, we're updating the model's\", 'internal parameters through additional', 'training. So the model starts out with', 'some weights here like', 'this. And those weights were optimized', 'during its initial pre-training. And as', \"we fine-tune, we're making small\", \"adjustments here to the model's weights\", 'using this specialized data set. So this', 'is being', 'incorporated. Now this process typically', 'uses supervised learning where we', 'provide input output pairs that', 'demonstrate the kind of responses we', \"want. So for example, if we're\", 'fine-tuning for technical support, we', 'might provide thousands of examples of', 'customer queries and those would be', 'paired with correct technical responses.', 'The model adjusts its weight through', 'back propagation to minimize the', 'difference between its predicted outputs', \"and the targeted responses. So we're not\", 'just teaching the model new facts here.', \"We're actually modifying how it\", 'processes information. The model is', 'learning to recognize domain specific', 'patterns. So fine-tuning shows its', 'strength when you particularly need a', 'model that has very deep', 'domain', \"expertise. That's what we can really add\", \"in with fine-tuning and also it's much\", 'faster specifically at inference time.', 'So when we are putting the queries in,', \"it's faster than rag because it doesn't\", 'need to search through external data.', 'And because the knowledge is kind of', \"baked into the model's weights, you\", \"don't need to maintain a separate vector\", \"database. But there's some downsides as\", \"well. Well, there's certainly issues\", 'here with the training complexity of all', \"of this. You're going to need thousands\", 'of high quality training examples. There', 'are', 'also issues with computational cost. The', 'computational cost for training this', 'model can be substantial and is going to', 'require a whole bunch of GPUs. And', \"there's also challenges related to\", 'maintenance as well because unlike rag', 'where you can easily add new documents', 'to your knowledge base at any point,', 'updating a fine-tune model requires', 'another round of training. And then', 'perhaps most importantly of all, there', 'is a risk of something called', \"catastrophic forgetting. Now that's\", 'where the model loses some of its', \"general capabilities while it's busy\", 'learning these specialized ones. So', \"finally, let's explore prompt\", 'engineering. Now specifying Martin Keen', 'who works at IBM versus Martin Keen who', \"founded Keen Shoes. That's prompt\", 'engineering. But at its most basic,', 'prompt engineering goes far beyond', \"simple clarification. So let's think\", 'about when we input a prompt, the model', 'receives this prompt and it processes it', 'through a series of', 'layers. And these layers are essentially', 'attention mechanisms. And each one', 'focuses on different aspects of your', 'prompt text that came in. And by', 'including specific elements in your', 'prompt, so examples or context or how', \"you want the format to look, you're\", \"directing the model's attention to\", 'relevant patterns it learned during', 'training. So for example, telling a', 'model to think about this step by step', 'that activates patterns it learned from', 'training data where methodical reasoning', 'led to accurate results. So a', 'wellengineered prompt can transform a', \"model's output without any additional\", 'training or without data retrieval. So', \"take an example of a of a prompt. Let's\", \"say we say is this code secure. It's not\", 'a very good prompt. An engineer prompt.', \"It might read a bit more like this. It's\", \"much more detailed. Now we haven't\", \"changed the model. We haven't added new\", \"data. we've just better activated its\", 'existing capabilities. Now, I think the', 'benefits to this are pretty obvious. One', \"is that we don't need to change any of\", 'our backend infrastructure here because', 'there are no infrastructure changes at', \"all in order to prompt better. It's all\", \"on the user. There's also the benefit\", 'that by doing this you get to see', 'immediate', 'responses and immediate results to what', \"you do. We don't have to add in new\", 'training data or any kind of data', 'processing. But of course there are some', 'limitations to this as well. Prompt', 'engineering is as much an art as it is a', 'science. So there is certainly a good', 'amount of trial and error in this sort', 'of process to find effective prompts.', \"And you're also limited in what you can\", \"do here. You're limited to existing\", \"knowledge because you're not able to\", 'actually add anything else in here. No', 'additional amount of prompt engineering', 'is going to teach it truly new', \"information. you're not going to teach\", \"the model anything that's outdated in\", \"the model. So we've talked about now rag\", 'as being one option and we talked about', 'fine tuning as being another one and now', \"just now we've talked about prompt\", \"engineering as well and I've really\", 'talked about those as three different', \"distinct things here but they're\", 'commonly used actually in combination.', 'We might use all three together. So', 'consider a legal AI system. Rag that', 'could retrieve specific cases and recent', 'court decisions. Uh the prompt', 'engineering part that could make sure', 'that we follow proper legal document', 'formats by asking for it. And then', 'fine-tuning that could help the model', 'master firm specific policies. I mean', 'basically we can think of it like this.', 'We can think that prompt engineering', 'offers flexibility and immediate results', \"but it can't extend knowledge. Rag that\", 'can extend knowledge. It provides', 'upto-date information but with', 'computational overhead and then', 'fine-tuning that enables deep domain', 'expertise but it requires significant', 'resources and maintenance. Basically it', 'comes down to picking the methods that', \"work for you. You know, we've we sure\", 'come a long way from vanity searching on', 'Google']\n",
      "‚úÖ Transcript saved as 'transcript.txt' and 'transcript.json'\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "import webvtt\n",
    "import json\n",
    "import os\n",
    "\n",
    "# === Step 1: Download subtitles using yt-dlp ===\n",
    "video_url = \"https://www.youtube.com/watch?v=zYGDpG-pTho&t=456s\"\n",
    "\n",
    "options = {\n",
    "    'skip_download': True,\n",
    "    'writesubtitles': False,\n",
    "    'writeautomaticsub': True,\n",
    "    'subtitleslangs': ['en'],\n",
    "    'subtitlesformat': 'vtt',\n",
    "    'outtmpl': 'transcript_temp.%(ext)s',  # Constant subtitle filename\n",
    "    'noplaylist': True\n",
    "}\n",
    "\n",
    "with yt_dlp.YoutubeDL(options) as ydl:\n",
    "    ydl.download([video_url])\n",
    "\n",
    "# === Step 2: Parse and save transcript in TXT and JSON formats ===\n",
    "vtt_filename = \"transcript_temp.en.vtt\"\n",
    "\n",
    "if os.path.exists(vtt_filename):\n",
    "    transcript_list = []\n",
    "    transcript_text = \"\"\n",
    "\n",
    "    for caption in webvtt.read(vtt_filename):\n",
    "        line = caption.text.strip()\n",
    "        transcript_list.append({\n",
    "            \"start\": caption.start,\n",
    "            \"end\": caption.end,\n",
    "            \"text\": line\n",
    "        })\n",
    "        transcript_text += line + \"\\n\"\n",
    "    \n",
    "\n",
    "    transcript_text = transcript_text.strip()\n",
    "    lines_list = transcript_text.splitlines()\n",
    "\n",
    "    # Remove consecutive duplicates\n",
    "    cleaned_lines = []\n",
    "    previous_line = None\n",
    "    for line in lines_list:\n",
    "        if line != previous_line:\n",
    "            cleaned_lines.append(line)\n",
    "        previous_line = line\n",
    "\n",
    "    print(cleaned_lines)\n",
    "\n",
    "\n",
    "    # Save TXT file\n",
    "    with open(\"transcript.txt\", \"w\", encoding=\"utf-8\") as txt_out:\n",
    "        txt_out.write(transcript_text)\n",
    "\n",
    "    # Save JSON file\n",
    "    with open(\"transcript.json\", \"w\", encoding=\"utf-8\") as json_out:\n",
    "        json.dump(transcript_list, json_out, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"‚úÖ Transcript saved as 'transcript.txt' and 'transcript.json'\")\n",
    "else:\n",
    "    print(\"‚ùå Subtitle file not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0208f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading subtitles...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=zYGDpG-pTho&t=456s\n",
      "[youtube] zYGDpG-pTho: Downloading webpage\n",
      "[youtube] zYGDpG-pTho: Downloading tv client config\n",
      "[youtube] zYGDpG-pTho: Downloading tv player API JSON\n",
      "[youtube] zYGDpG-pTho: Downloading ios player API JSON\n",
      "[youtube] zYGDpG-pTho: Downloading player fc2a56a5-main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] zYGDpG-pTho: nsig extraction failed: Some formats may be missing\n",
      "         n = VZ8oEHrBdLVKMaD ; player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] zYGDpG-pTho: nsig extraction failed: Some formats may be missing\n",
      "         n = Vl3vnTA0suz2ZDL ; player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] zYGDpG-pTho: nsig extraction failed: Some formats may be missing\n",
      "         n = rwYz1uhP2ec12qc ; player = https://www.youtube.com/s/player/fc2a56a5/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] zYGDpG-pTho: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] zYGDpG-pTho: Downloading m3u8 information\n",
      "[info] zYGDpG-pTho: Downloading subtitles: en\n",
      "[info] zYGDpG-pTho: Downloading 1 format(s): 616+234\n",
      "Deleting existing file transcript_temp.en.vtt\n",
      "[info] Writing video subtitles to: transcript_temp.en.vtt\n",
      "[download] Destination: transcript_temp.en.vtt\n",
      "[download] 100% of   90.44KiB in 00:00:00 at 280.15KiB/s\n",
      "üìÑ Processing subtitle file...\n",
      "Remember how back in the day people\n",
      "would Google themselves? You type your\n",
      "name into a search engine and you see\n",
      "what it knows about you? Well, the\n",
      "modern equivalent of that is to do the\n",
      "same thing with a chatbot. So, when I\n",
      "ask a large language model, who is\n",
      "Martin Keen? Well, the response varies\n",
      "greatly depending upon which model I'm\n",
      "asking because different models, they\n",
      "have different training data sets. They\n",
      "have different knowledge cutoff dates.\n",
      "So what a given model knows about me?\n",
      "Well, it differs greatly. But how could\n",
      "we improve the model's answer? Well,\n",
      "there's three ways. So let's start with\n",
      "a model here. And we're going to see how\n",
      "we can improve its responses. Well, the\n",
      "first thing it could do is it could go\n",
      "out and it could perform a search. a\n",
      "search for new data that either wasn't\n",
      "in its training data set or it was just\n",
      "data that became available after the\n",
      "model finished training. And then it\n",
      "could incorporate those results from the\n",
      "search back into its answer. That is\n",
      "called rag or retrieval augmented\n",
      "generation. That's one method. Or we\n",
      "could pick a specialized model, a model\n",
      "that's been trained on, let's say,\n",
      "transcripts of these videos. That would\n",
      "be an example of something called fine\n",
      "tuning. Or we could ask the model a\n",
      "query that better specifies what we're\n",
      "looking for. So maybe the LLM already\n",
      "knows plenty about the Martin Keen of\n",
      "the world, but let's tell the model that\n",
      "we're referring to the Martin Keen who\n",
      "works at IBM rather than the Martin Keen\n",
      "that founded Keen Shoes. That is an\n",
      "example of prompt\n",
      "engineering. Three ways to get better\n",
      "outputs out of large language models,\n",
      "each with their pluses and\n",
      "minuses. Let's start with rag. So, let's\n",
      "break it down. First, there's retrieval.\n",
      "So, retrieval of external up-to-ate\n",
      "information. Then, there's augmentation.\n",
      "That's augmentation of the original\n",
      "prompt with the retrieved information\n",
      "added in. And then, finally, there's\n",
      "generation. That's generation of a\n",
      "response based on all of this enriched\n",
      "context. So, we can think of it like\n",
      "this. So we start with a query and the\n",
      "query comes in to a large language\n",
      "model. Now what rag is going to do is\n",
      "it's first going to go searching through\n",
      "a corpus of information. So we have this\n",
      "corpus here full of some sort of data.\n",
      "Now perhaps that's your organization's\n",
      "documents. So it might be spreadsheets,\n",
      "PDFs, internal wiks, you know, stuff\n",
      "like that. But unlike a typical search\n",
      "engine that just matches keywords, Rag\n",
      "converts both your question, the query,\n",
      "and all of the documents into something\n",
      "called\n",
      "vector\n",
      "embeddings. So these are all converted\n",
      "into vectors. essentially turning words\n",
      "and phrases into long lists of numbers\n",
      "that capture their meaning. So when you\n",
      "ask a query like what was our company's\n",
      "revenue growth last quarter? Well, Rag\n",
      "will find documents that are\n",
      "mathematically similar in meaning to\n",
      "your question, even if they don't use\n",
      "the exact same words. So it might find\n",
      "documents mentioning fourth quarter\n",
      "performance or quarterly sales. Those\n",
      "don't contain the keyword revenue\n",
      "growth, but they are semantically\n",
      "similar. Now, once rag finds the\n",
      "relevant information, it adds this\n",
      "information back into your original\n",
      "query before passing it to the language\n",
      "model. So instead of the model just kind\n",
      "of guessing based on its training data,\n",
      "it can now generate a response that\n",
      "incorporates your actual facts and\n",
      "figures. So this makes rag particularly\n",
      "valuable when you are looking for\n",
      "information that is up to date and it's\n",
      "also very valuable when you need in to\n",
      "add in information that is domain\n",
      "specific as\n",
      "well. But there are some costs to this.\n",
      "Let's go with the red pen. So one cost\n",
      "that would be the cost of performance\n",
      "for performing all of this because you\n",
      "have this retrieval step here and that\n",
      "adds latency to each query compared to a\n",
      "simple prompt to a model. There are also\n",
      "costs related to just kind of the the\n",
      "processing of this as well. So if we\n",
      "think about what we having to do here,\n",
      "we've got documents that need to be\n",
      "vector embeddings and we need to store\n",
      "these vector embeddings in a database.\n",
      "All of this adds to processing costs. It\n",
      "adds to infrastructure costs to make\n",
      "this solution work. All right, next up,\n",
      "fine tuning. So remember how we\n",
      "discussed getting better answers about\n",
      "me by training a model specifically on\n",
      "let's say my video transcripts? Well,\n",
      "that is fine tuning in action. So what\n",
      "we do with fine-tuning is we take a\n",
      "model but specifically an existing model\n",
      "and that existing model has broad\n",
      "knowledge and then we're going to give\n",
      "it additional specialized training on a\n",
      "focused data set. So this is now\n",
      "specialized to what we want to develop\n",
      "particular expertise on. Now during\n",
      "fine-tuning, we're updating the model's\n",
      "internal parameters through additional\n",
      "training. So the model starts out with\n",
      "some weights here like\n",
      "this. And those weights were optimized\n",
      "during its initial pre-training. And as\n",
      "we fine-tune, we're making small\n",
      "adjustments here to the model's weights\n",
      "using this specialized data set. So this\n",
      "is being\n",
      "incorporated. Now this process typically\n",
      "uses supervised learning where we\n",
      "provide input output pairs that\n",
      "demonstrate the kind of responses we\n",
      "want. So for example, if we're\n",
      "fine-tuning for technical support, we\n",
      "might provide thousands of examples of\n",
      "customer queries and those would be\n",
      "paired with correct technical responses.\n",
      "The model adjusts its weight through\n",
      "back propagation to minimize the\n",
      "difference between its predicted outputs\n",
      "and the targeted responses. So we're not\n",
      "just teaching the model new facts here.\n",
      "We're actually modifying how it\n",
      "processes information. The model is\n",
      "learning to recognize domain specific\n",
      "patterns. So fine-tuning shows its\n",
      "strength when you particularly need a\n",
      "model that has very deep\n",
      "domain\n",
      "expertise. That's what we can really add\n",
      "in with fine-tuning and also it's much\n",
      "faster specifically at inference time.\n",
      "So when we are putting the queries in,\n",
      "it's faster than rag because it doesn't\n",
      "need to search through external data.\n",
      "And because the knowledge is kind of\n",
      "baked into the model's weights, you\n",
      "don't need to maintain a separate vector\n",
      "database. But there's some downsides as\n",
      "well. Well, there's certainly issues\n",
      "here with the training complexity of all\n",
      "of this. You're going to need thousands\n",
      "of high quality training examples. There\n",
      "are\n",
      "also issues with computational cost. The\n",
      "computational cost for training this\n",
      "model can be substantial and is going to\n",
      "require a whole bunch of GPUs. And\n",
      "there's also challenges related to\n",
      "maintenance as well because unlike rag\n",
      "where you can easily add new documents\n",
      "to your knowledge base at any point,\n",
      "updating a fine-tune model requires\n",
      "another round of training. And then\n",
      "perhaps most importantly of all, there\n",
      "is a risk of something called\n",
      "catastrophic forgetting. Now that's\n",
      "where the model loses some of its\n",
      "general capabilities while it's busy\n",
      "learning these specialized ones. So\n",
      "finally, let's explore prompt\n",
      "engineering. Now specifying Martin Keen\n",
      "who works at IBM versus Martin Keen who\n",
      "founded Keen Shoes. That's prompt\n",
      "engineering. But at its most basic,\n",
      "prompt engineering goes far beyond\n",
      "simple clarification. So let's think\n",
      "about when we input a prompt, the model\n",
      "receives this prompt and it processes it\n",
      "through a series of\n",
      "layers. And these layers are essentially\n",
      "attention mechanisms. And each one\n",
      "focuses on different aspects of your\n",
      "prompt text that came in. And by\n",
      "including specific elements in your\n",
      "prompt, so examples or context or how\n",
      "you want the format to look, you're\n",
      "directing the model's attention to\n",
      "relevant patterns it learned during\n",
      "training. So for example, telling a\n",
      "model to think about this step by step\n",
      "that activates patterns it learned from\n",
      "training data where methodical reasoning\n",
      "led to accurate results. So a\n",
      "wellengineered prompt can transform a\n",
      "model's output without any additional\n",
      "training or without data retrieval. So\n",
      "take an example of a of a prompt. Let's\n",
      "say we say is this code secure. It's not\n",
      "a very good prompt. An engineer prompt.\n",
      "It might read a bit more like this. It's\n",
      "much more detailed. Now we haven't\n",
      "changed the model. We haven't added new\n",
      "data. we've just better activated its\n",
      "existing capabilities. Now, I think the\n",
      "benefits to this are pretty obvious. One\n",
      "is that we don't need to change any of\n",
      "our backend infrastructure here because\n",
      "there are no infrastructure changes at\n",
      "all in order to prompt better. It's all\n",
      "on the user. There's also the benefit\n",
      "that by doing this you get to see\n",
      "immediate\n",
      "responses and immediate results to what\n",
      "you do. We don't have to add in new\n",
      "training data or any kind of data\n",
      "processing. But of course there are some\n",
      "limitations to this as well. Prompt\n",
      "engineering is as much an art as it is a\n",
      "science. So there is certainly a good\n",
      "amount of trial and error in this sort\n",
      "of process to find effective prompts.\n",
      "And you're also limited in what you can\n",
      "do here. You're limited to existing\n",
      "knowledge because you're not able to\n",
      "actually add anything else in here. No\n",
      "additional amount of prompt engineering\n",
      "is going to teach it truly new\n",
      "information. you're not going to teach\n",
      "the model anything that's outdated in\n",
      "the model. So we've talked about now rag\n",
      "as being one option and we talked about\n",
      "fine tuning as being another one and now\n",
      "just now we've talked about prompt\n",
      "engineering as well and I've really\n",
      "talked about those as three different\n",
      "distinct things here but they're\n",
      "commonly used actually in combination.\n",
      "We might use all three together. So\n",
      "consider a legal AI system. Rag that\n",
      "could retrieve specific cases and recent\n",
      "court decisions. Uh the prompt\n",
      "engineering part that could make sure\n",
      "that we follow proper legal document\n",
      "formats by asking for it. And then\n",
      "fine-tuning that could help the model\n",
      "master firm specific policies. I mean\n",
      "basically we can think of it like this.\n",
      "We can think that prompt engineering\n",
      "offers flexibility and immediate results\n",
      "but it can't extend knowledge. Rag that\n",
      "can extend knowledge. It provides\n",
      "upto-date information but with\n",
      "computational overhead and then\n",
      "fine-tuning that enables deep domain\n",
      "expertise but it requires significant\n",
      "resources and maintenance. Basically it\n",
      "comes down to picking the methods that\n",
      "work for you. You know, we've we sure\n",
      "come a long way from vanity searching on\n",
      "Google\n",
      "\n",
      "\n",
      "[{'start': '00:00:02.869', 'end': '00:00:02.879', 'text': 'Remember how back in the day people'}, {'start': '00:00:02.879', 'end': '00:00:04.950', 'text': 'Remember how back in the day people\\nwould Google themselves? You type your'}, {'start': '00:00:04.950', 'end': '00:00:04.960', 'text': 'would Google themselves? You type your'}, {'start': '00:00:04.960', 'end': '00:00:07.110', 'text': 'would Google themselves? You type your\\nname into a search engine and you see'}, {'start': '00:00:07.110', 'end': '00:00:07.120', 'text': 'name into a search engine and you see'}, {'start': '00:00:07.120', 'end': '00:00:08.870', 'text': 'name into a search engine and you see\\nwhat it knows about you? Well, the'}, {'start': '00:00:08.870', 'end': '00:00:08.880', 'text': 'what it knows about you? Well, the'}, {'start': '00:00:08.880', 'end': '00:00:10.709', 'text': 'what it knows about you? Well, the\\nmodern equivalent of that is to do the'}, {'start': '00:00:10.709', 'end': '00:00:10.719', 'text': 'modern equivalent of that is to do the'}, {'start': '00:00:10.719', 'end': '00:00:14.070', 'text': 'modern equivalent of that is to do the\\nsame thing with a chatbot. So, when I'}, {'start': '00:00:14.070', 'end': '00:00:14.080', 'text': 'same thing with a chatbot. So, when I'}, {'start': '00:00:14.080', 'end': '00:00:16.950', 'text': 'same thing with a chatbot. So, when I\\nask a large language model, who is'}, {'start': '00:00:16.950', 'end': '00:00:16.960', 'text': 'ask a large language model, who is'}, {'start': '00:00:16.960', 'end': '00:00:20.150', 'text': 'ask a large language model, who is\\nMartin Keen? Well, the response varies'}, {'start': '00:00:20.150', 'end': '00:00:20.160', 'text': 'Martin Keen? Well, the response varies'}, {'start': '00:00:20.160', 'end': '00:00:22.630', 'text': \"Martin Keen? Well, the response varies\\ngreatly depending upon which model I'm\"}, {'start': '00:00:22.630', 'end': '00:00:22.640', 'text': \"greatly depending upon which model I'm\"}, {'start': '00:00:22.640', 'end': '00:00:24.150', 'text': \"greatly depending upon which model I'm\\nasking because different models, they\"}, {'start': '00:00:24.150', 'end': '00:00:24.160', 'text': 'asking because different models, they'}, {'start': '00:00:24.160', 'end': '00:00:25.830', 'text': 'asking because different models, they\\nhave different training data sets. They'}, {'start': '00:00:25.830', 'end': '00:00:25.840', 'text': 'have different training data sets. They'}, {'start': '00:00:25.840', 'end': '00:00:27.910', 'text': 'have different training data sets. They\\nhave different knowledge cutoff dates.'}, {'start': '00:00:27.910', 'end': '00:00:27.920', 'text': 'have different knowledge cutoff dates.'}, {'start': '00:00:27.920', 'end': '00:00:31.029', 'text': 'have different knowledge cutoff dates.\\nSo what a given model knows about me?'}, {'start': '00:00:31.029', 'end': '00:00:31.039', 'text': 'So what a given model knows about me?'}, {'start': '00:00:31.039', 'end': '00:00:33.190', 'text': 'So what a given model knows about me?\\nWell, it differs greatly. But how could'}, {'start': '00:00:33.190', 'end': '00:00:33.200', 'text': 'Well, it differs greatly. But how could'}, {'start': '00:00:33.200', 'end': '00:00:36.470', 'text': \"Well, it differs greatly. But how could\\nwe improve the model's answer? Well,\"}, {'start': '00:00:36.470', 'end': '00:00:36.480', 'text': \"we improve the model's answer? Well,\"}, {'start': '00:00:36.480', 'end': '00:00:39.670', 'text': \"we improve the model's answer? Well,\\nthere's three ways. So let's start with\"}, {'start': '00:00:39.670', 'end': '00:00:39.680', 'text': \"there's three ways. So let's start with\"}, {'start': '00:00:39.680', 'end': '00:00:42.869', 'text': \"there's three ways. So let's start with\\na model here. And we're going to see how\"}, {'start': '00:00:42.869', 'end': '00:00:42.879', 'text': \"a model here. And we're going to see how\"}, {'start': '00:00:42.879', 'end': '00:00:45.270', 'text': \"a model here. And we're going to see how\\nwe can improve its responses. Well, the\"}, {'start': '00:00:45.270', 'end': '00:00:45.280', 'text': 'we can improve its responses. Well, the'}, {'start': '00:00:45.280', 'end': '00:00:47.510', 'text': 'we can improve its responses. Well, the\\nfirst thing it could do is it could go'}, {'start': '00:00:47.510', 'end': '00:00:47.520', 'text': 'first thing it could do is it could go'}, {'start': '00:00:47.520', 'end': '00:00:51.350', 'text': 'first thing it could do is it could go\\nout and it could perform a search. a'}, {'start': '00:00:51.350', 'end': '00:00:51.360', 'text': 'out and it could perform a search. a'}, {'start': '00:00:51.360', 'end': '00:00:53.270', 'text': \"out and it could perform a search. a\\nsearch for new data that either wasn't\"}, {'start': '00:00:53.270', 'end': '00:00:53.280', 'text': \"search for new data that either wasn't\"}, {'start': '00:00:53.280', 'end': '00:00:55.430', 'text': \"search for new data that either wasn't\\nin its training data set or it was just\"}, {'start': '00:00:55.430', 'end': '00:00:55.440', 'text': 'in its training data set or it was just'}, {'start': '00:00:55.440', 'end': '00:00:57.350', 'text': 'in its training data set or it was just\\ndata that became available after the'}, {'start': '00:00:57.350', 'end': '00:00:57.360', 'text': 'data that became available after the'}, {'start': '00:00:57.360', 'end': '00:00:59.270', 'text': 'data that became available after the\\nmodel finished training. And then it'}, {'start': '00:00:59.270', 'end': '00:00:59.280', 'text': 'model finished training. And then it'}, {'start': '00:00:59.280', 'end': '00:01:01.349', 'text': 'model finished training. And then it\\ncould incorporate those results from the'}, {'start': '00:01:01.349', 'end': '00:01:01.359', 'text': 'could incorporate those results from the'}, {'start': '00:01:01.359', 'end': '00:01:04.910', 'text': 'could incorporate those results from the\\nsearch back into its answer. That is'}, {'start': '00:01:04.910', 'end': '00:01:04.920', 'text': 'search back into its answer. That is'}, {'start': '00:01:04.920', 'end': '00:01:10.270', 'text': 'search back into its answer. That is\\ncalled rag or retrieval augmented'}, {'start': '00:01:10.270', 'end': '00:01:10.280', 'text': 'called rag or retrieval augmented'}, {'start': '00:01:10.280', 'end': '00:01:13.350', 'text': \"called rag or retrieval augmented\\ngeneration. That's one method. Or we\"}, {'start': '00:01:13.350', 'end': '00:01:13.360', 'text': \"generation. That's one method. Or we\"}, {'start': '00:01:13.360', 'end': '00:01:17.350', 'text': \"generation. That's one method. Or we\\ncould pick a specialized model, a model\"}, {'start': '00:01:17.350', 'end': '00:01:17.360', 'text': 'could pick a specialized model, a model'}, {'start': '00:01:17.360', 'end': '00:01:19.190', 'text': \"could pick a specialized model, a model\\nthat's been trained on, let's say,\"}, {'start': '00:01:19.190', 'end': '00:01:19.200', 'text': \"that's been trained on, let's say,\"}, {'start': '00:01:19.200', 'end': '00:01:22.390', 'text': \"that's been trained on, let's say,\\ntranscripts of these videos. That would\"}, {'start': '00:01:22.390', 'end': '00:01:22.400', 'text': 'transcripts of these videos. That would'}, {'start': '00:01:22.400', 'end': '00:01:28.190', 'text': 'transcripts of these videos. That would\\nbe an example of something called fine'}, {'start': '00:01:28.190', 'end': '00:01:28.200', 'text': 'be an example of something called fine'}, {'start': '00:01:28.200', 'end': '00:01:32.550', 'text': 'be an example of something called fine\\ntuning. Or we could ask the model a'}, {'start': '00:01:32.550', 'end': '00:01:32.560', 'text': 'tuning. Or we could ask the model a'}, {'start': '00:01:32.560', 'end': '00:01:35.830', 'text': \"tuning. Or we could ask the model a\\nquery that better specifies what we're\"}, {'start': '00:01:35.830', 'end': '00:01:35.840', 'text': \"query that better specifies what we're\"}, {'start': '00:01:35.840', 'end': '00:01:38.550', 'text': \"query that better specifies what we're\\nlooking for. So maybe the LLM already\"}, {'start': '00:01:38.550', 'end': '00:01:38.560', 'text': 'looking for. So maybe the LLM already'}, {'start': '00:01:38.560', 'end': '00:01:41.109', 'text': 'looking for. So maybe the LLM already\\nknows plenty about the Martin Keen of'}, {'start': '00:01:41.109', 'end': '00:01:41.119', 'text': 'knows plenty about the Martin Keen of'}, {'start': '00:01:41.119', 'end': '00:01:43.429', 'text': \"knows plenty about the Martin Keen of\\nthe world, but let's tell the model that\"}, {'start': '00:01:43.429', 'end': '00:01:43.439', 'text': \"the world, but let's tell the model that\"}, {'start': '00:01:43.439', 'end': '00:01:44.950', 'text': \"the world, but let's tell the model that\\nwe're referring to the Martin Keen who\"}, {'start': '00:01:44.950', 'end': '00:01:44.960', 'text': \"we're referring to the Martin Keen who\"}, {'start': '00:01:44.960', 'end': '00:01:47.590', 'text': \"we're referring to the Martin Keen who\\nworks at IBM rather than the Martin Keen\"}, {'start': '00:01:47.590', 'end': '00:01:47.600', 'text': 'works at IBM rather than the Martin Keen'}, {'start': '00:01:47.600', 'end': '00:01:51.469', 'text': 'works at IBM rather than the Martin Keen\\nthat founded Keen Shoes. That is an'}, {'start': '00:01:51.469', 'end': '00:01:51.479', 'text': 'that founded Keen Shoes. That is an'}, {'start': '00:01:51.479', 'end': '00:01:54.990', 'text': 'that founded Keen Shoes. That is an\\nexample of prompt'}, {'start': '00:01:54.990', 'end': '00:01:55.000', 'text': 'example of prompt'}, {'start': '00:01:55.000', 'end': '00:01:57.990', 'text': 'example of prompt\\nengineering. Three ways to get better'}, {'start': '00:01:57.990', 'end': '00:01:58.000', 'text': 'engineering. Three ways to get better'}, {'start': '00:01:58.000', 'end': '00:02:00.230', 'text': 'engineering. Three ways to get better\\noutputs out of large language models,'}, {'start': '00:02:00.230', 'end': '00:02:00.240', 'text': 'outputs out of large language models,'}, {'start': '00:02:00.240', 'end': '00:02:02.510', 'text': 'outputs out of large language models,\\neach with their pluses and'}, {'start': '00:02:02.510', 'end': '00:02:02.520', 'text': 'each with their pluses and'}, {'start': '00:02:02.520', 'end': '00:02:05.830', 'text': \"each with their pluses and\\nminuses. Let's start with rag. So, let's\"}, {'start': '00:02:05.830', 'end': '00:02:05.840', 'text': \"minuses. Let's start with rag. So, let's\"}, {'start': '00:02:05.840', 'end': '00:02:08.630', 'text': \"minuses. Let's start with rag. So, let's\\nbreak it down. First, there's retrieval.\"}, {'start': '00:02:08.630', 'end': '00:02:08.640', 'text': \"break it down. First, there's retrieval.\"}, {'start': '00:02:08.640', 'end': '00:02:11.350', 'text': \"break it down. First, there's retrieval.\\nSo, retrieval of external up-to-ate\"}, {'start': '00:02:11.350', 'end': '00:02:11.360', 'text': 'So, retrieval of external up-to-ate'}, {'start': '00:02:11.360', 'end': '00:02:14.790', 'text': \"So, retrieval of external up-to-ate\\ninformation. Then, there's augmentation.\"}, {'start': '00:02:14.790', 'end': '00:02:14.800', 'text': \"information. Then, there's augmentation.\"}, {'start': '00:02:14.800', 'end': '00:02:16.630', 'text': \"information. Then, there's augmentation.\\nThat's augmentation of the original\"}, {'start': '00:02:16.630', 'end': '00:02:16.640', 'text': \"That's augmentation of the original\"}, {'start': '00:02:16.640', 'end': '00:02:18.790', 'text': \"That's augmentation of the original\\nprompt with the retrieved information\"}, {'start': '00:02:18.790', 'end': '00:02:18.800', 'text': 'prompt with the retrieved information'}, {'start': '00:02:18.800', 'end': '00:02:21.150', 'text': \"prompt with the retrieved information\\nadded in. And then, finally, there's\"}, {'start': '00:02:21.150', 'end': '00:02:21.160', 'text': \"added in. And then, finally, there's\"}, {'start': '00:02:21.160', 'end': '00:02:23.589', 'text': \"added in. And then, finally, there's\\ngeneration. That's generation of a\"}, {'start': '00:02:23.589', 'end': '00:02:23.599', 'text': \"generation. That's generation of a\"}, {'start': '00:02:23.599', 'end': '00:02:26.990', 'text': \"generation. That's generation of a\\nresponse based on all of this enriched\"}, {'start': '00:02:26.990', 'end': '00:02:27.000', 'text': 'response based on all of this enriched'}, {'start': '00:02:27.000', 'end': '00:02:29.910', 'text': 'response based on all of this enriched\\ncontext. So, we can think of it like'}, {'start': '00:02:29.910', 'end': '00:02:29.920', 'text': 'context. So, we can think of it like'}, {'start': '00:02:29.920', 'end': '00:02:34.309', 'text': 'context. So, we can think of it like\\nthis. So we start with a query and the'}, {'start': '00:02:34.309', 'end': '00:02:34.319', 'text': 'this. So we start with a query and the'}, {'start': '00:02:34.319', 'end': '00:02:39.270', 'text': 'this. So we start with a query and the\\nquery comes in to a large language'}, {'start': '00:02:39.270', 'end': '00:02:39.280', 'text': 'query comes in to a large language'}, {'start': '00:02:39.280', 'end': '00:02:42.070', 'text': 'query comes in to a large language\\nmodel. Now what rag is going to do is'}, {'start': '00:02:42.070', 'end': '00:02:42.080', 'text': 'model. Now what rag is going to do is'}, {'start': '00:02:42.080', 'end': '00:02:45.350', 'text': \"model. Now what rag is going to do is\\nit's first going to go searching through\"}, {'start': '00:02:45.350', 'end': '00:02:45.360', 'text': \"it's first going to go searching through\"}, {'start': '00:02:45.360', 'end': '00:02:49.990', 'text': \"it's first going to go searching through\\na corpus of information. So we have this\"}, {'start': '00:02:49.990', 'end': '00:02:50.000', 'text': 'a corpus of information. So we have this'}, {'start': '00:02:50.000', 'end': '00:02:53.750', 'text': 'a corpus of information. So we have this\\ncorpus here full of some sort of data.'}, {'start': '00:02:53.750', 'end': '00:02:53.760', 'text': 'corpus here full of some sort of data.'}, {'start': '00:02:53.760', 'end': '00:02:56.470', 'text': \"corpus here full of some sort of data.\\nNow perhaps that's your organization's\"}, {'start': '00:02:56.470', 'end': '00:02:56.480', 'text': \"Now perhaps that's your organization's\"}, {'start': '00:02:56.480', 'end': '00:02:58.390', 'text': \"Now perhaps that's your organization's\\ndocuments. So it might be spreadsheets,\"}, {'start': '00:02:58.390', 'end': '00:02:58.400', 'text': 'documents. So it might be spreadsheets,'}, {'start': '00:02:58.400', 'end': '00:03:00.470', 'text': 'documents. So it might be spreadsheets,\\nPDFs, internal wiks, you know, stuff'}, {'start': '00:03:00.470', 'end': '00:03:00.480', 'text': 'PDFs, internal wiks, you know, stuff'}, {'start': '00:03:00.480', 'end': '00:03:04.229', 'text': 'PDFs, internal wiks, you know, stuff\\nlike that. But unlike a typical search'}, {'start': '00:03:04.229', 'end': '00:03:04.239', 'text': 'like that. But unlike a typical search'}, {'start': '00:03:04.239', 'end': '00:03:08.070', 'text': 'like that. But unlike a typical search\\nengine that just matches keywords, Rag'}, {'start': '00:03:08.070', 'end': '00:03:08.080', 'text': 'engine that just matches keywords, Rag'}, {'start': '00:03:08.080', 'end': '00:03:10.630', 'text': 'engine that just matches keywords, Rag\\nconverts both your question, the query,'}, {'start': '00:03:10.630', 'end': '00:03:10.640', 'text': 'converts both your question, the query,'}, {'start': '00:03:10.640', 'end': '00:03:13.869', 'text': 'converts both your question, the query,\\nand all of the documents into something'}, {'start': '00:03:13.869', 'end': '00:03:13.879', 'text': 'and all of the documents into something'}, {'start': '00:03:13.879', 'end': '00:03:15.550', 'text': 'and all of the documents into something\\ncalled'}, {'start': '00:03:15.550', 'end': '00:03:15.560', 'text': 'called'}, {'start': '00:03:15.560', 'end': '00:03:17.229', 'text': 'called\\nvector'}, {'start': '00:03:17.229', 'end': '00:03:17.239', 'text': 'vector'}, {'start': '00:03:17.239', 'end': '00:03:19.509', 'text': 'vector\\nembeddings. So these are all converted'}, {'start': '00:03:19.509', 'end': '00:03:19.519', 'text': 'embeddings. So these are all converted'}, {'start': '00:03:19.519', 'end': '00:03:22.710', 'text': 'embeddings. So these are all converted\\ninto vectors. essentially turning words'}, {'start': '00:03:22.710', 'end': '00:03:22.720', 'text': 'into vectors. essentially turning words'}, {'start': '00:03:22.720', 'end': '00:03:25.589', 'text': 'into vectors. essentially turning words\\nand phrases into long lists of numbers'}, {'start': '00:03:25.589', 'end': '00:03:25.599', 'text': 'and phrases into long lists of numbers'}, {'start': '00:03:25.599', 'end': '00:03:28.229', 'text': 'and phrases into long lists of numbers\\nthat capture their meaning. So when you'}, {'start': '00:03:28.229', 'end': '00:03:28.239', 'text': 'that capture their meaning. So when you'}, {'start': '00:03:28.239', 'end': '00:03:31.589', 'text': \"that capture their meaning. So when you\\nask a query like what was our company's\"}, {'start': '00:03:31.589', 'end': '00:03:31.599', 'text': \"ask a query like what was our company's\"}, {'start': '00:03:31.599', 'end': '00:03:34.789', 'text': \"ask a query like what was our company's\\nrevenue growth last quarter? Well, Rag\"}, {'start': '00:03:34.789', 'end': '00:03:34.799', 'text': 'revenue growth last quarter? Well, Rag'}, {'start': '00:03:34.799', 'end': '00:03:36.070', 'text': 'revenue growth last quarter? Well, Rag\\nwill find documents that are'}, {'start': '00:03:36.070', 'end': '00:03:36.080', 'text': 'will find documents that are'}, {'start': '00:03:36.080', 'end': '00:03:37.990', 'text': 'will find documents that are\\nmathematically similar in meaning to'}, {'start': '00:03:37.990', 'end': '00:03:38.000', 'text': 'mathematically similar in meaning to'}, {'start': '00:03:38.000', 'end': '00:03:40.550', 'text': \"mathematically similar in meaning to\\nyour question, even if they don't use\"}, {'start': '00:03:40.550', 'end': '00:03:40.560', 'text': \"your question, even if they don't use\"}, {'start': '00:03:40.560', 'end': '00:03:43.430', 'text': \"your question, even if they don't use\\nthe exact same words. So it might find\"}, {'start': '00:03:43.430', 'end': '00:03:43.440', 'text': 'the exact same words. So it might find'}, {'start': '00:03:43.440', 'end': '00:03:45.589', 'text': 'the exact same words. So it might find\\ndocuments mentioning fourth quarter'}, {'start': '00:03:45.589', 'end': '00:03:45.599', 'text': 'documents mentioning fourth quarter'}, {'start': '00:03:45.599', 'end': '00:03:48.710', 'text': 'documents mentioning fourth quarter\\nperformance or quarterly sales. Those'}, {'start': '00:03:48.710', 'end': '00:03:48.720', 'text': 'performance or quarterly sales. Those'}, {'start': '00:03:48.720', 'end': '00:03:50.869', 'text': \"performance or quarterly sales. Those\\ndon't contain the keyword revenue\"}, {'start': '00:03:50.869', 'end': '00:03:50.879', 'text': \"don't contain the keyword revenue\"}, {'start': '00:03:50.879', 'end': '00:03:53.869', 'text': \"don't contain the keyword revenue\\ngrowth, but they are semantically\"}, {'start': '00:03:53.869', 'end': '00:03:53.879', 'text': 'growth, but they are semantically'}, {'start': '00:03:53.879', 'end': '00:03:56.390', 'text': 'growth, but they are semantically\\nsimilar. Now, once rag finds the'}, {'start': '00:03:56.390', 'end': '00:03:56.400', 'text': 'similar. Now, once rag finds the'}, {'start': '00:03:56.400', 'end': '00:03:58.949', 'text': 'similar. Now, once rag finds the\\nrelevant information, it adds this'}, {'start': '00:03:58.949', 'end': '00:03:58.959', 'text': 'relevant information, it adds this'}, {'start': '00:03:58.959', 'end': '00:04:01.830', 'text': 'relevant information, it adds this\\ninformation back into your original'}, {'start': '00:04:01.830', 'end': '00:04:01.840', 'text': 'information back into your original'}, {'start': '00:04:01.840', 'end': '00:04:05.270', 'text': 'information back into your original\\nquery before passing it to the language'}, {'start': '00:04:05.270', 'end': '00:04:05.280', 'text': 'query before passing it to the language'}, {'start': '00:04:05.280', 'end': '00:04:07.509', 'text': 'query before passing it to the language\\nmodel. So instead of the model just kind'}, {'start': '00:04:07.509', 'end': '00:04:07.519', 'text': 'model. So instead of the model just kind'}, {'start': '00:04:07.519', 'end': '00:04:09.830', 'text': 'model. So instead of the model just kind\\nof guessing based on its training data,'}, {'start': '00:04:09.830', 'end': '00:04:09.840', 'text': 'of guessing based on its training data,'}, {'start': '00:04:09.840', 'end': '00:04:11.750', 'text': 'of guessing based on its training data,\\nit can now generate a response that'}, {'start': '00:04:11.750', 'end': '00:04:11.760', 'text': 'it can now generate a response that'}, {'start': '00:04:11.760', 'end': '00:04:14.550', 'text': 'it can now generate a response that\\nincorporates your actual facts and'}, {'start': '00:04:14.550', 'end': '00:04:14.560', 'text': 'incorporates your actual facts and'}, {'start': '00:04:14.560', 'end': '00:04:18.629', 'text': 'incorporates your actual facts and\\nfigures. So this makes rag particularly'}, {'start': '00:04:18.629', 'end': '00:04:18.639', 'text': 'figures. So this makes rag particularly'}, {'start': '00:04:18.639', 'end': '00:04:20.710', 'text': 'figures. So this makes rag particularly\\nvaluable when you are looking for'}, {'start': '00:04:20.710', 'end': '00:04:20.720', 'text': 'valuable when you are looking for'}, {'start': '00:04:20.720', 'end': '00:04:25.510', 'text': \"valuable when you are looking for\\ninformation that is up to date and it's\"}, {'start': '00:04:25.510', 'end': '00:04:25.520', 'text': \"information that is up to date and it's\"}, {'start': '00:04:25.520', 'end': '00:04:28.550', 'text': \"information that is up to date and it's\\nalso very valuable when you need in to\"}, {'start': '00:04:28.550', 'end': '00:04:28.560', 'text': 'also very valuable when you need in to'}, {'start': '00:04:28.560', 'end': '00:04:32.150', 'text': 'also very valuable when you need in to\\nadd in information that is domain'}, {'start': '00:04:32.150', 'end': '00:04:32.160', 'text': 'add in information that is domain'}, {'start': '00:04:32.160', 'end': '00:04:33.870', 'text': 'add in information that is domain\\nspecific as'}, {'start': '00:04:33.870', 'end': '00:04:33.880', 'text': 'specific as'}, {'start': '00:04:33.880', 'end': '00:04:37.670', 'text': 'specific as\\nwell. But there are some costs to this.'}, {'start': '00:04:37.670', 'end': '00:04:37.680', 'text': 'well. But there are some costs to this.'}, {'start': '00:04:37.680', 'end': '00:04:41.909', 'text': \"well. But there are some costs to this.\\nLet's go with the red pen. So one cost\"}, {'start': '00:04:41.909', 'end': '00:04:41.919', 'text': \"Let's go with the red pen. So one cost\"}, {'start': '00:04:41.919', 'end': '00:04:45.749', 'text': \"Let's go with the red pen. So one cost\\nthat would be the cost of performance\"}, {'start': '00:04:45.749', 'end': '00:04:45.759', 'text': 'that would be the cost of performance'}, {'start': '00:04:45.759', 'end': '00:04:48.070', 'text': 'that would be the cost of performance\\nfor performing all of this because you'}, {'start': '00:04:48.070', 'end': '00:04:48.080', 'text': 'for performing all of this because you'}, {'start': '00:04:48.080', 'end': '00:04:50.070', 'text': 'for performing all of this because you\\nhave this retrieval step here and that'}, {'start': '00:04:50.070', 'end': '00:04:50.080', 'text': 'have this retrieval step here and that'}, {'start': '00:04:50.080', 'end': '00:04:53.110', 'text': 'have this retrieval step here and that\\nadds latency to each query compared to a'}, {'start': '00:04:53.110', 'end': '00:04:53.120', 'text': 'adds latency to each query compared to a'}, {'start': '00:04:53.120', 'end': '00:04:56.150', 'text': 'adds latency to each query compared to a\\nsimple prompt to a model. There are also'}, {'start': '00:04:56.150', 'end': '00:04:56.160', 'text': 'simple prompt to a model. There are also'}, {'start': '00:04:56.160', 'end': '00:04:59.990', 'text': 'simple prompt to a model. There are also\\ncosts related to just kind of the the'}, {'start': '00:04:59.990', 'end': '00:05:00.000', 'text': 'costs related to just kind of the the'}, {'start': '00:05:00.000', 'end': '00:05:01.990', 'text': 'costs related to just kind of the the\\nprocessing of this as well. So if we'}, {'start': '00:05:01.990', 'end': '00:05:02.000', 'text': 'processing of this as well. So if we'}, {'start': '00:05:02.000', 'end': '00:05:04.629', 'text': 'processing of this as well. So if we\\nthink about what we having to do here,'}, {'start': '00:05:04.629', 'end': '00:05:04.639', 'text': 'think about what we having to do here,'}, {'start': '00:05:04.639', 'end': '00:05:06.710', 'text': \"think about what we having to do here,\\nwe've got documents that need to be\"}, {'start': '00:05:06.710', 'end': '00:05:06.720', 'text': \"we've got documents that need to be\"}, {'start': '00:05:06.720', 'end': '00:05:08.790', 'text': \"we've got documents that need to be\\nvector embeddings and we need to store\"}, {'start': '00:05:08.790', 'end': '00:05:08.800', 'text': 'vector embeddings and we need to store'}, {'start': '00:05:08.800', 'end': '00:05:11.510', 'text': 'vector embeddings and we need to store\\nthese vector embeddings in a database.'}, {'start': '00:05:11.510', 'end': '00:05:11.520', 'text': 'these vector embeddings in a database.'}, {'start': '00:05:11.520', 'end': '00:05:13.510', 'text': 'these vector embeddings in a database.\\nAll of this adds to processing costs. It'}, {'start': '00:05:13.510', 'end': '00:05:13.520', 'text': 'All of this adds to processing costs. It'}, {'start': '00:05:13.520', 'end': '00:05:15.670', 'text': 'All of this adds to processing costs. It\\nadds to infrastructure costs to make'}, {'start': '00:05:15.670', 'end': '00:05:15.680', 'text': 'adds to infrastructure costs to make'}, {'start': '00:05:15.680', 'end': '00:05:18.590', 'text': 'adds to infrastructure costs to make\\nthis solution work. All right, next up,'}, {'start': '00:05:18.590', 'end': '00:05:18.600', 'text': 'this solution work. All right, next up,'}, {'start': '00:05:18.600', 'end': '00:05:21.029', 'text': 'this solution work. All right, next up,\\nfine tuning. So remember how we'}, {'start': '00:05:21.029', 'end': '00:05:21.039', 'text': 'fine tuning. So remember how we'}, {'start': '00:05:21.039', 'end': '00:05:23.110', 'text': 'fine tuning. So remember how we\\ndiscussed getting better answers about'}, {'start': '00:05:23.110', 'end': '00:05:23.120', 'text': 'discussed getting better answers about'}, {'start': '00:05:23.120', 'end': '00:05:25.510', 'text': 'discussed getting better answers about\\nme by training a model specifically on'}, {'start': '00:05:25.510', 'end': '00:05:25.520', 'text': 'me by training a model specifically on'}, {'start': '00:05:25.520', 'end': '00:05:27.110', 'text': \"me by training a model specifically on\\nlet's say my video transcripts? Well,\"}, {'start': '00:05:27.110', 'end': '00:05:27.120', 'text': \"let's say my video transcripts? Well,\"}, {'start': '00:05:27.120', 'end': '00:05:31.430', 'text': \"let's say my video transcripts? Well,\\nthat is fine tuning in action. So what\"}, {'start': '00:05:31.430', 'end': '00:05:31.440', 'text': 'that is fine tuning in action. So what'}, {'start': '00:05:31.440', 'end': '00:05:35.110', 'text': 'that is fine tuning in action. So what\\nwe do with fine-tuning is we take a'}, {'start': '00:05:35.110', 'end': '00:05:35.120', 'text': 'we do with fine-tuning is we take a'}, {'start': '00:05:35.120', 'end': '00:05:40.550', 'text': 'we do with fine-tuning is we take a\\nmodel but specifically an existing model'}, {'start': '00:05:40.550', 'end': '00:05:40.560', 'text': 'model but specifically an existing model'}, {'start': '00:05:40.560', 'end': '00:05:43.510', 'text': 'model but specifically an existing model\\nand that existing model has broad'}, {'start': '00:05:43.510', 'end': '00:05:43.520', 'text': 'and that existing model has broad'}, {'start': '00:05:43.520', 'end': '00:05:45.110', 'text': \"and that existing model has broad\\nknowledge and then we're going to give\"}, {'start': '00:05:45.110', 'end': '00:05:45.120', 'text': \"knowledge and then we're going to give\"}, {'start': '00:05:45.120', 'end': '00:05:49.749', 'text': \"knowledge and then we're going to give\\nit additional specialized training on a\"}, {'start': '00:05:49.749', 'end': '00:05:49.759', 'text': 'it additional specialized training on a'}, {'start': '00:05:49.759', 'end': '00:05:53.189', 'text': 'it additional specialized training on a\\nfocused data set. So this is now'}, {'start': '00:05:53.189', 'end': '00:05:53.199', 'text': 'focused data set. So this is now'}, {'start': '00:05:53.199', 'end': '00:05:56.310', 'text': 'focused data set. So this is now\\nspecialized to what we want to develop'}, {'start': '00:05:56.310', 'end': '00:05:56.320', 'text': 'specialized to what we want to develop'}, {'start': '00:05:56.320', 'end': '00:05:59.430', 'text': 'specialized to what we want to develop\\nparticular expertise on. Now during'}, {'start': '00:05:59.430', 'end': '00:05:59.440', 'text': 'particular expertise on. Now during'}, {'start': '00:05:59.440', 'end': '00:06:01.670', 'text': \"particular expertise on. Now during\\nfine-tuning, we're updating the model's\"}, {'start': '00:06:01.670', 'end': '00:06:01.680', 'text': \"fine-tuning, we're updating the model's\"}, {'start': '00:06:01.680', 'end': '00:06:04.870', 'text': \"fine-tuning, we're updating the model's\\ninternal parameters through additional\"}, {'start': '00:06:04.870', 'end': '00:06:04.880', 'text': 'internal parameters through additional'}, {'start': '00:06:04.880', 'end': '00:06:08.150', 'text': 'internal parameters through additional\\ntraining. So the model starts out with'}, {'start': '00:06:08.150', 'end': '00:06:08.160', 'text': 'training. So the model starts out with'}, {'start': '00:06:08.160', 'end': '00:06:11.390', 'text': 'training. So the model starts out with\\nsome weights here like'}, {'start': '00:06:11.390', 'end': '00:06:11.400', 'text': 'some weights here like'}, {'start': '00:06:11.400', 'end': '00:06:13.990', 'text': 'some weights here like\\nthis. And those weights were optimized'}, {'start': '00:06:13.990', 'end': '00:06:14.000', 'text': 'this. And those weights were optimized'}, {'start': '00:06:14.000', 'end': '00:06:16.629', 'text': 'this. And those weights were optimized\\nduring its initial pre-training. And as'}, {'start': '00:06:16.629', 'end': '00:06:16.639', 'text': 'during its initial pre-training. And as'}, {'start': '00:06:16.639', 'end': '00:06:19.830', 'text': \"during its initial pre-training. And as\\nwe fine-tune, we're making small\"}, {'start': '00:06:19.830', 'end': '00:06:19.840', 'text': \"we fine-tune, we're making small\"}, {'start': '00:06:19.840', 'end': '00:06:23.590', 'text': \"we fine-tune, we're making small\\nadjustments here to the model's weights\"}, {'start': '00:06:23.590', 'end': '00:06:23.600', 'text': \"adjustments here to the model's weights\"}, {'start': '00:06:23.600', 'end': '00:06:26.870', 'text': \"adjustments here to the model's weights\\nusing this specialized data set. So this\"}, {'start': '00:06:26.870', 'end': '00:06:26.880', 'text': 'using this specialized data set. So this'}, {'start': '00:06:26.880', 'end': '00:06:28.430', 'text': 'using this specialized data set. So this\\nis being'}, {'start': '00:06:28.430', 'end': '00:06:28.440', 'text': 'is being'}, {'start': '00:06:28.440', 'end': '00:06:30.950', 'text': 'is being\\nincorporated. Now this process typically'}, {'start': '00:06:30.950', 'end': '00:06:30.960', 'text': 'incorporated. Now this process typically'}, {'start': '00:06:30.960', 'end': '00:06:33.270', 'text': 'incorporated. Now this process typically\\nuses supervised learning where we'}, {'start': '00:06:33.270', 'end': '00:06:33.280', 'text': 'uses supervised learning where we'}, {'start': '00:06:33.280', 'end': '00:06:35.430', 'text': 'uses supervised learning where we\\nprovide input output pairs that'}, {'start': '00:06:35.430', 'end': '00:06:35.440', 'text': 'provide input output pairs that'}, {'start': '00:06:35.440', 'end': '00:06:37.430', 'text': 'provide input output pairs that\\ndemonstrate the kind of responses we'}, {'start': '00:06:37.430', 'end': '00:06:37.440', 'text': 'demonstrate the kind of responses we'}, {'start': '00:06:37.440', 'end': '00:06:39.430', 'text': \"demonstrate the kind of responses we\\nwant. So for example, if we're\"}, {'start': '00:06:39.430', 'end': '00:06:39.440', 'text': \"want. So for example, if we're\"}, {'start': '00:06:39.440', 'end': '00:06:41.590', 'text': \"want. So for example, if we're\\nfine-tuning for technical support, we\"}, {'start': '00:06:41.590', 'end': '00:06:41.600', 'text': 'fine-tuning for technical support, we'}, {'start': '00:06:41.600', 'end': '00:06:44.390', 'text': 'fine-tuning for technical support, we\\nmight provide thousands of examples of'}, {'start': '00:06:44.390', 'end': '00:06:44.400', 'text': 'might provide thousands of examples of'}, {'start': '00:06:44.400', 'end': '00:06:47.029', 'text': 'might provide thousands of examples of\\ncustomer queries and those would be'}, {'start': '00:06:47.029', 'end': '00:06:47.039', 'text': 'customer queries and those would be'}, {'start': '00:06:47.039', 'end': '00:06:50.390', 'text': 'customer queries and those would be\\npaired with correct technical responses.'}, {'start': '00:06:50.390', 'end': '00:06:50.400', 'text': 'paired with correct technical responses.'}, {'start': '00:06:50.400', 'end': '00:06:52.870', 'text': 'paired with correct technical responses.\\nThe model adjusts its weight through'}, {'start': '00:06:52.870', 'end': '00:06:52.880', 'text': 'The model adjusts its weight through'}, {'start': '00:06:52.880', 'end': '00:06:55.110', 'text': 'The model adjusts its weight through\\nback propagation to minimize the'}, {'start': '00:06:55.110', 'end': '00:06:55.120', 'text': 'back propagation to minimize the'}, {'start': '00:06:55.120', 'end': '00:06:56.710', 'text': 'back propagation to minimize the\\ndifference between its predicted outputs'}, {'start': '00:06:56.710', 'end': '00:06:56.720', 'text': 'difference between its predicted outputs'}, {'start': '00:06:56.720', 'end': '00:06:59.830', 'text': \"difference between its predicted outputs\\nand the targeted responses. So we're not\"}, {'start': '00:06:59.830', 'end': '00:06:59.840', 'text': \"and the targeted responses. So we're not\"}, {'start': '00:06:59.840', 'end': '00:07:02.390', 'text': \"and the targeted responses. So we're not\\njust teaching the model new facts here.\"}, {'start': '00:07:02.390', 'end': '00:07:02.400', 'text': 'just teaching the model new facts here.'}, {'start': '00:07:02.400', 'end': '00:07:04.749', 'text': \"just teaching the model new facts here.\\nWe're actually modifying how it\"}, {'start': '00:07:04.749', 'end': '00:07:04.759', 'text': \"We're actually modifying how it\"}, {'start': '00:07:04.759', 'end': '00:07:07.510', 'text': \"We're actually modifying how it\\nprocesses information. The model is\"}, {'start': '00:07:07.510', 'end': '00:07:07.520', 'text': 'processes information. The model is'}, {'start': '00:07:07.520', 'end': '00:07:10.309', 'text': 'processes information. The model is\\nlearning to recognize domain specific'}, {'start': '00:07:10.309', 'end': '00:07:10.319', 'text': 'learning to recognize domain specific'}, {'start': '00:07:10.319', 'end': '00:07:13.670', 'text': 'learning to recognize domain specific\\npatterns. So fine-tuning shows its'}, {'start': '00:07:13.670', 'end': '00:07:13.680', 'text': 'patterns. So fine-tuning shows its'}, {'start': '00:07:13.680', 'end': '00:07:15.670', 'text': 'patterns. So fine-tuning shows its\\nstrength when you particularly need a'}, {'start': '00:07:15.670', 'end': '00:07:15.680', 'text': 'strength when you particularly need a'}, {'start': '00:07:15.680', 'end': '00:07:19.629', 'text': 'strength when you particularly need a\\nmodel that has very deep'}, {'start': '00:07:19.629', 'end': '00:07:19.639', 'text': 'model that has very deep'}, {'start': '00:07:19.639', 'end': '00:07:21.230', 'text': 'model that has very deep\\ndomain'}, {'start': '00:07:21.230', 'end': '00:07:21.240', 'text': 'domain'}, {'start': '00:07:21.240', 'end': '00:07:23.589', 'text': \"domain\\nexpertise. That's what we can really add\"}, {'start': '00:07:23.589', 'end': '00:07:23.599', 'text': \"expertise. That's what we can really add\"}, {'start': '00:07:23.599', 'end': '00:07:28.029', 'text': \"expertise. That's what we can really add\\nin with fine-tuning and also it's much\"}, {'start': '00:07:28.029', 'end': '00:07:28.039', 'text': \"in with fine-tuning and also it's much\"}, {'start': '00:07:28.039', 'end': '00:07:31.189', 'text': \"in with fine-tuning and also it's much\\nfaster specifically at inference time.\"}, {'start': '00:07:31.189', 'end': '00:07:31.199', 'text': 'faster specifically at inference time.'}, {'start': '00:07:31.199', 'end': '00:07:33.749', 'text': 'faster specifically at inference time.\\nSo when we are putting the queries in,'}, {'start': '00:07:33.749', 'end': '00:07:33.759', 'text': 'So when we are putting the queries in,'}, {'start': '00:07:33.759', 'end': '00:07:35.430', 'text': \"So when we are putting the queries in,\\nit's faster than rag because it doesn't\"}, {'start': '00:07:35.430', 'end': '00:07:35.440', 'text': \"it's faster than rag because it doesn't\"}, {'start': '00:07:35.440', 'end': '00:07:38.150', 'text': \"it's faster than rag because it doesn't\\nneed to search through external data.\"}, {'start': '00:07:38.150', 'end': '00:07:38.160', 'text': 'need to search through external data.'}, {'start': '00:07:38.160', 'end': '00:07:39.430', 'text': 'need to search through external data.\\nAnd because the knowledge is kind of'}, {'start': '00:07:39.430', 'end': '00:07:39.440', 'text': 'And because the knowledge is kind of'}, {'start': '00:07:39.440', 'end': '00:07:41.510', 'text': \"And because the knowledge is kind of\\nbaked into the model's weights, you\"}, {'start': '00:07:41.510', 'end': '00:07:41.520', 'text': \"baked into the model's weights, you\"}, {'start': '00:07:41.520', 'end': '00:07:43.270', 'text': \"baked into the model's weights, you\\ndon't need to maintain a separate vector\"}, {'start': '00:07:43.270', 'end': '00:07:43.280', 'text': \"don't need to maintain a separate vector\"}, {'start': '00:07:43.280', 'end': '00:07:46.309', 'text': \"don't need to maintain a separate vector\\ndatabase. But there's some downsides as\"}, {'start': '00:07:46.309', 'end': '00:07:46.319', 'text': \"database. But there's some downsides as\"}, {'start': '00:07:46.319', 'end': '00:07:49.430', 'text': \"database. But there's some downsides as\\nwell. Well, there's certainly issues\"}, {'start': '00:07:49.430', 'end': '00:07:49.440', 'text': \"well. Well, there's certainly issues\"}, {'start': '00:07:49.440', 'end': '00:07:53.189', 'text': \"well. Well, there's certainly issues\\nhere with the training complexity of all\"}, {'start': '00:07:53.189', 'end': '00:07:53.199', 'text': 'here with the training complexity of all'}, {'start': '00:07:53.199', 'end': '00:07:55.990', 'text': \"here with the training complexity of all\\nof this. You're going to need thousands\"}, {'start': '00:07:55.990', 'end': '00:07:56.000', 'text': \"of this. You're going to need thousands\"}, {'start': '00:07:56.000', 'end': '00:08:00.230', 'text': \"of this. You're going to need thousands\\nof high quality training examples. There\"}, {'start': '00:08:00.230', 'end': '00:08:00.240', 'text': 'of high quality training examples. There'}, {'start': '00:08:00.240', 'end': '00:08:01.150', 'text': 'of high quality training examples. There\\nare'}, {'start': '00:08:01.150', 'end': '00:08:01.160', 'text': 'are'}, {'start': '00:08:01.160', 'end': '00:08:06.150', 'text': 'are\\nalso issues with computational cost. The'}, {'start': '00:08:06.150', 'end': '00:08:06.160', 'text': 'also issues with computational cost. The'}, {'start': '00:08:06.160', 'end': '00:08:07.909', 'text': 'also issues with computational cost. The\\ncomputational cost for training this'}, {'start': '00:08:07.909', 'end': '00:08:07.919', 'text': 'computational cost for training this'}, {'start': '00:08:07.919', 'end': '00:08:09.670', 'text': 'computational cost for training this\\nmodel can be substantial and is going to'}, {'start': '00:08:09.670', 'end': '00:08:09.680', 'text': 'model can be substantial and is going to'}, {'start': '00:08:09.680', 'end': '00:08:12.550', 'text': 'model can be substantial and is going to\\nrequire a whole bunch of GPUs. And'}, {'start': '00:08:12.550', 'end': '00:08:12.560', 'text': 'require a whole bunch of GPUs. And'}, {'start': '00:08:12.560', 'end': '00:08:15.990', 'text': \"require a whole bunch of GPUs. And\\nthere's also challenges related to\"}, {'start': '00:08:15.990', 'end': '00:08:16.000', 'text': \"there's also challenges related to\"}, {'start': '00:08:16.000', 'end': '00:08:18.869', 'text': \"there's also challenges related to\\nmaintenance as well because unlike rag\"}, {'start': '00:08:18.869', 'end': '00:08:18.879', 'text': 'maintenance as well because unlike rag'}, {'start': '00:08:18.879', 'end': '00:08:20.550', 'text': 'maintenance as well because unlike rag\\nwhere you can easily add new documents'}, {'start': '00:08:20.550', 'end': '00:08:20.560', 'text': 'where you can easily add new documents'}, {'start': '00:08:20.560', 'end': '00:08:22.550', 'text': 'where you can easily add new documents\\nto your knowledge base at any point,'}, {'start': '00:08:22.550', 'end': '00:08:22.560', 'text': 'to your knowledge base at any point,'}, {'start': '00:08:22.560', 'end': '00:08:25.510', 'text': 'to your knowledge base at any point,\\nupdating a fine-tune model requires'}, {'start': '00:08:25.510', 'end': '00:08:25.520', 'text': 'updating a fine-tune model requires'}, {'start': '00:08:25.520', 'end': '00:08:27.430', 'text': 'updating a fine-tune model requires\\nanother round of training. And then'}, {'start': '00:08:27.430', 'end': '00:08:27.440', 'text': 'another round of training. And then'}, {'start': '00:08:27.440', 'end': '00:08:30.950', 'text': 'another round of training. And then\\nperhaps most importantly of all, there'}, {'start': '00:08:30.950', 'end': '00:08:30.960', 'text': 'perhaps most importantly of all, there'}, {'start': '00:08:30.960', 'end': '00:08:35.310', 'text': 'perhaps most importantly of all, there\\nis a risk of something called'}, {'start': '00:08:35.310', 'end': '00:08:35.320', 'text': 'is a risk of something called'}, {'start': '00:08:35.320', 'end': '00:08:37.750', 'text': \"is a risk of something called\\ncatastrophic forgetting. Now that's\"}, {'start': '00:08:37.750', 'end': '00:08:37.760', 'text': \"catastrophic forgetting. Now that's\"}, {'start': '00:08:37.760', 'end': '00:08:40.070', 'text': \"catastrophic forgetting. Now that's\\nwhere the model loses some of its\"}, {'start': '00:08:40.070', 'end': '00:08:40.080', 'text': 'where the model loses some of its'}, {'start': '00:08:40.080', 'end': '00:08:42.469', 'text': \"where the model loses some of its\\ngeneral capabilities while it's busy\"}, {'start': '00:08:42.469', 'end': '00:08:42.479', 'text': \"general capabilities while it's busy\"}, {'start': '00:08:42.479', 'end': '00:08:44.949', 'text': \"general capabilities while it's busy\\nlearning these specialized ones. So\"}, {'start': '00:08:44.949', 'end': '00:08:44.959', 'text': 'learning these specialized ones. So'}, {'start': '00:08:44.959', 'end': '00:08:47.790', 'text': \"learning these specialized ones. So\\nfinally, let's explore prompt\"}, {'start': '00:08:47.790', 'end': '00:08:47.800', 'text': \"finally, let's explore prompt\"}, {'start': '00:08:47.800', 'end': '00:08:50.790', 'text': \"finally, let's explore prompt\\nengineering. Now specifying Martin Keen\"}, {'start': '00:08:50.790', 'end': '00:08:50.800', 'text': 'engineering. Now specifying Martin Keen'}, {'start': '00:08:50.800', 'end': '00:08:53.509', 'text': 'engineering. Now specifying Martin Keen\\nwho works at IBM versus Martin Keen who'}, {'start': '00:08:53.509', 'end': '00:08:53.519', 'text': 'who works at IBM versus Martin Keen who'}, {'start': '00:08:53.519', 'end': '00:08:55.430', 'text': \"who works at IBM versus Martin Keen who\\nfounded Keen Shoes. That's prompt\"}, {'start': '00:08:55.430', 'end': '00:08:55.440', 'text': \"founded Keen Shoes. That's prompt\"}, {'start': '00:08:55.440', 'end': '00:08:57.829', 'text': \"founded Keen Shoes. That's prompt\\nengineering. But at its most basic,\"}, {'start': '00:08:57.829', 'end': '00:08:57.839', 'text': 'engineering. But at its most basic,'}, {'start': '00:08:57.839', 'end': '00:08:59.910', 'text': 'engineering. But at its most basic,\\nprompt engineering goes far beyond'}, {'start': '00:08:59.910', 'end': '00:08:59.920', 'text': 'prompt engineering goes far beyond'}, {'start': '00:08:59.920', 'end': '00:09:02.870', 'text': \"prompt engineering goes far beyond\\nsimple clarification. So let's think\"}, {'start': '00:09:02.870', 'end': '00:09:02.880', 'text': \"simple clarification. So let's think\"}, {'start': '00:09:02.880', 'end': '00:09:07.350', 'text': \"simple clarification. So let's think\\nabout when we input a prompt, the model\"}, {'start': '00:09:07.350', 'end': '00:09:07.360', 'text': 'about when we input a prompt, the model'}, {'start': '00:09:07.360', 'end': '00:09:11.509', 'text': 'about when we input a prompt, the model\\nreceives this prompt and it processes it'}, {'start': '00:09:11.509', 'end': '00:09:11.519', 'text': 'receives this prompt and it processes it'}, {'start': '00:09:11.519', 'end': '00:09:15.470', 'text': 'receives this prompt and it processes it\\nthrough a series of'}, {'start': '00:09:15.470', 'end': '00:09:15.480', 'text': 'through a series of'}, {'start': '00:09:15.480', 'end': '00:09:19.030', 'text': 'through a series of\\nlayers. And these layers are essentially'}, {'start': '00:09:19.030', 'end': '00:09:19.040', 'text': 'layers. And these layers are essentially'}, {'start': '00:09:19.040', 'end': '00:09:21.509', 'text': 'layers. And these layers are essentially\\nattention mechanisms. And each one'}, {'start': '00:09:21.509', 'end': '00:09:21.519', 'text': 'attention mechanisms. And each one'}, {'start': '00:09:21.519', 'end': '00:09:23.750', 'text': 'attention mechanisms. And each one\\nfocuses on different aspects of your'}, {'start': '00:09:23.750', 'end': '00:09:23.760', 'text': 'focuses on different aspects of your'}, {'start': '00:09:23.760', 'end': '00:09:26.070', 'text': 'focuses on different aspects of your\\nprompt text that came in. And by'}, {'start': '00:09:26.070', 'end': '00:09:26.080', 'text': 'prompt text that came in. And by'}, {'start': '00:09:26.080', 'end': '00:09:28.150', 'text': 'prompt text that came in. And by\\nincluding specific elements in your'}, {'start': '00:09:28.150', 'end': '00:09:28.160', 'text': 'including specific elements in your'}, {'start': '00:09:28.160', 'end': '00:09:31.430', 'text': 'including specific elements in your\\nprompt, so examples or context or how'}, {'start': '00:09:31.430', 'end': '00:09:31.440', 'text': 'prompt, so examples or context or how'}, {'start': '00:09:31.440', 'end': '00:09:33.590', 'text': \"prompt, so examples or context or how\\nyou want the format to look, you're\"}, {'start': '00:09:33.590', 'end': '00:09:33.600', 'text': \"you want the format to look, you're\"}, {'start': '00:09:33.600', 'end': '00:09:35.829', 'text': \"you want the format to look, you're\\ndirecting the model's attention to\"}, {'start': '00:09:35.829', 'end': '00:09:35.839', 'text': \"directing the model's attention to\"}, {'start': '00:09:35.839', 'end': '00:09:37.990', 'text': \"directing the model's attention to\\nrelevant patterns it learned during\"}, {'start': '00:09:37.990', 'end': '00:09:38.000', 'text': 'relevant patterns it learned during'}, {'start': '00:09:38.000', 'end': '00:09:40.070', 'text': 'relevant patterns it learned during\\ntraining. So for example, telling a'}, {'start': '00:09:40.070', 'end': '00:09:40.080', 'text': 'training. So for example, telling a'}, {'start': '00:09:40.080', 'end': '00:09:43.190', 'text': 'training. So for example, telling a\\nmodel to think about this step by step'}, {'start': '00:09:43.190', 'end': '00:09:43.200', 'text': 'model to think about this step by step'}, {'start': '00:09:43.200', 'end': '00:09:45.750', 'text': 'model to think about this step by step\\nthat activates patterns it learned from'}, {'start': '00:09:45.750', 'end': '00:09:45.760', 'text': 'that activates patterns it learned from'}, {'start': '00:09:45.760', 'end': '00:09:48.070', 'text': 'that activates patterns it learned from\\ntraining data where methodical reasoning'}, {'start': '00:09:48.070', 'end': '00:09:48.080', 'text': 'training data where methodical reasoning'}, {'start': '00:09:48.080', 'end': '00:09:50.670', 'text': 'training data where methodical reasoning\\nled to accurate results. So a'}, {'start': '00:09:50.670', 'end': '00:09:50.680', 'text': 'led to accurate results. So a'}, {'start': '00:09:50.680', 'end': '00:09:54.470', 'text': 'led to accurate results. So a\\nwellengineered prompt can transform a'}, {'start': '00:09:54.470', 'end': '00:09:54.480', 'text': 'wellengineered prompt can transform a'}, {'start': '00:09:54.480', 'end': '00:09:57.269', 'text': \"wellengineered prompt can transform a\\nmodel's output without any additional\"}, {'start': '00:09:57.269', 'end': '00:09:57.279', 'text': \"model's output without any additional\"}, {'start': '00:09:57.279', 'end': '00:10:00.310', 'text': \"model's output without any additional\\ntraining or without data retrieval. So\"}, {'start': '00:10:00.310', 'end': '00:10:00.320', 'text': 'training or without data retrieval. So'}, {'start': '00:10:00.320', 'end': '00:10:03.110', 'text': \"training or without data retrieval. So\\ntake an example of a of a prompt. Let's\"}, {'start': '00:10:03.110', 'end': '00:10:03.120', 'text': \"take an example of a of a prompt. Let's\"}, {'start': '00:10:03.120', 'end': '00:10:06.710', 'text': \"take an example of a of a prompt. Let's\\nsay we say is this code secure. It's not\"}, {'start': '00:10:06.710', 'end': '00:10:06.720', 'text': \"say we say is this code secure. It's not\"}, {'start': '00:10:06.720', 'end': '00:10:09.350', 'text': \"say we say is this code secure. It's not\\na very good prompt. An engineer prompt.\"}, {'start': '00:10:09.350', 'end': '00:10:09.360', 'text': 'a very good prompt. An engineer prompt.'}, {'start': '00:10:09.360', 'end': '00:10:12.550', 'text': \"a very good prompt. An engineer prompt.\\nIt might read a bit more like this. It's\"}, {'start': '00:10:12.550', 'end': '00:10:12.560', 'text': \"It might read a bit more like this. It's\"}, {'start': '00:10:12.560', 'end': '00:10:15.590', 'text': \"It might read a bit more like this. It's\\nmuch more detailed. Now we haven't\"}, {'start': '00:10:15.590', 'end': '00:10:15.600', 'text': \"much more detailed. Now we haven't\"}, {'start': '00:10:15.600', 'end': '00:10:17.590', 'text': \"much more detailed. Now we haven't\\nchanged the model. We haven't added new\"}, {'start': '00:10:17.590', 'end': '00:10:17.600', 'text': \"changed the model. We haven't added new\"}, {'start': '00:10:17.600', 'end': '00:10:20.949', 'text': \"changed the model. We haven't added new\\ndata. we've just better activated its\"}, {'start': '00:10:20.949', 'end': '00:10:20.959', 'text': \"data. we've just better activated its\"}, {'start': '00:10:20.959', 'end': '00:10:23.750', 'text': \"data. we've just better activated its\\nexisting capabilities. Now, I think the\"}, {'start': '00:10:23.750', 'end': '00:10:23.760', 'text': 'existing capabilities. Now, I think the'}, {'start': '00:10:23.760', 'end': '00:10:27.190', 'text': 'existing capabilities. Now, I think the\\nbenefits to this are pretty obvious. One'}, {'start': '00:10:27.190', 'end': '00:10:27.200', 'text': 'benefits to this are pretty obvious. One'}, {'start': '00:10:27.200', 'end': '00:10:29.670', 'text': \"benefits to this are pretty obvious. One\\nis that we don't need to change any of\"}, {'start': '00:10:29.670', 'end': '00:10:29.680', 'text': \"is that we don't need to change any of\"}, {'start': '00:10:29.680', 'end': '00:10:32.949', 'text': \"is that we don't need to change any of\\nour backend infrastructure here because\"}, {'start': '00:10:32.949', 'end': '00:10:32.959', 'text': 'our backend infrastructure here because'}, {'start': '00:10:32.959', 'end': '00:10:35.269', 'text': 'our backend infrastructure here because\\nthere are no infrastructure changes at'}, {'start': '00:10:35.269', 'end': '00:10:35.279', 'text': 'there are no infrastructure changes at'}, {'start': '00:10:35.279', 'end': '00:10:38.230', 'text': \"there are no infrastructure changes at\\nall in order to prompt better. It's all\"}, {'start': '00:10:38.230', 'end': '00:10:38.240', 'text': \"all in order to prompt better. It's all\"}, {'start': '00:10:38.240', 'end': '00:10:41.350', 'text': \"all in order to prompt better. It's all\\non the user. There's also the benefit\"}, {'start': '00:10:41.350', 'end': '00:10:41.360', 'text': \"on the user. There's also the benefit\"}, {'start': '00:10:41.360', 'end': '00:10:43.829', 'text': \"on the user. There's also the benefit\\nthat by doing this you get to see\"}, {'start': '00:10:43.829', 'end': '00:10:43.839', 'text': 'that by doing this you get to see'}, {'start': '00:10:43.839', 'end': '00:10:45.230', 'text': 'that by doing this you get to see\\nimmediate'}, {'start': '00:10:45.230', 'end': '00:10:45.240', 'text': 'immediate'}, {'start': '00:10:45.240', 'end': '00:10:48.710', 'text': 'immediate\\nresponses and immediate results to what'}, {'start': '00:10:48.710', 'end': '00:10:48.720', 'text': 'responses and immediate results to what'}, {'start': '00:10:48.720', 'end': '00:10:51.670', 'text': \"responses and immediate results to what\\nyou do. We don't have to add in new\"}, {'start': '00:10:51.670', 'end': '00:10:51.680', 'text': \"you do. We don't have to add in new\"}, {'start': '00:10:51.680', 'end': '00:10:53.269', 'text': \"you do. We don't have to add in new\\ntraining data or any kind of data\"}, {'start': '00:10:53.269', 'end': '00:10:53.279', 'text': 'training data or any kind of data'}, {'start': '00:10:53.279', 'end': '00:10:55.509', 'text': 'training data or any kind of data\\nprocessing. But of course there are some'}, {'start': '00:10:55.509', 'end': '00:10:55.519', 'text': 'processing. But of course there are some'}, {'start': '00:10:55.519', 'end': '00:10:58.230', 'text': 'processing. But of course there are some\\nlimitations to this as well. Prompt'}, {'start': '00:10:58.230', 'end': '00:10:58.240', 'text': 'limitations to this as well. Prompt'}, {'start': '00:10:58.240', 'end': '00:11:01.030', 'text': 'limitations to this as well. Prompt\\nengineering is as much an art as it is a'}, {'start': '00:11:01.030', 'end': '00:11:01.040', 'text': 'engineering is as much an art as it is a'}, {'start': '00:11:01.040', 'end': '00:11:03.990', 'text': 'engineering is as much an art as it is a\\nscience. So there is certainly a good'}, {'start': '00:11:03.990', 'end': '00:11:04.000', 'text': 'science. So there is certainly a good'}, {'start': '00:11:04.000', 'end': '00:11:07.590', 'text': 'science. So there is certainly a good\\namount of trial and error in this sort'}, {'start': '00:11:07.590', 'end': '00:11:07.600', 'text': 'amount of trial and error in this sort'}, {'start': '00:11:07.600', 'end': '00:11:10.870', 'text': 'amount of trial and error in this sort\\nof process to find effective prompts.'}, {'start': '00:11:10.870', 'end': '00:11:10.880', 'text': 'of process to find effective prompts.'}, {'start': '00:11:10.880', 'end': '00:11:14.230', 'text': \"of process to find effective prompts.\\nAnd you're also limited in what you can\"}, {'start': '00:11:14.230', 'end': '00:11:14.240', 'text': \"And you're also limited in what you can\"}, {'start': '00:11:14.240', 'end': '00:11:18.069', 'text': \"And you're also limited in what you can\\ndo here. You're limited to existing\"}, {'start': '00:11:18.069', 'end': '00:11:18.079', 'text': \"do here. You're limited to existing\"}, {'start': '00:11:18.079', 'end': '00:11:21.150', 'text': \"do here. You're limited to existing\\nknowledge because you're not able to\"}, {'start': '00:11:21.150', 'end': '00:11:21.160', 'text': \"knowledge because you're not able to\"}, {'start': '00:11:21.160', 'end': '00:11:24.150', 'text': \"knowledge because you're not able to\\nactually add anything else in here. No\"}, {'start': '00:11:24.150', 'end': '00:11:24.160', 'text': 'actually add anything else in here. No'}, {'start': '00:11:24.160', 'end': '00:11:25.750', 'text': 'actually add anything else in here. No\\nadditional amount of prompt engineering'}, {'start': '00:11:25.750', 'end': '00:11:25.760', 'text': 'additional amount of prompt engineering'}, {'start': '00:11:25.760', 'end': '00:11:28.069', 'text': 'additional amount of prompt engineering\\nis going to teach it truly new'}, {'start': '00:11:28.069', 'end': '00:11:28.079', 'text': 'is going to teach it truly new'}, {'start': '00:11:28.079', 'end': '00:11:29.670', 'text': \"is going to teach it truly new\\ninformation. you're not going to teach\"}, {'start': '00:11:29.670', 'end': '00:11:29.680', 'text': \"information. you're not going to teach\"}, {'start': '00:11:29.680', 'end': '00:11:32.550', 'text': \"information. you're not going to teach\\nthe model anything that's outdated in\"}, {'start': '00:11:32.550', 'end': '00:11:32.560', 'text': \"the model anything that's outdated in\"}, {'start': '00:11:32.560', 'end': '00:11:37.430', 'text': \"the model anything that's outdated in\\nthe model. So we've talked about now rag\"}, {'start': '00:11:37.430', 'end': '00:11:37.440', 'text': \"the model. So we've talked about now rag\"}, {'start': '00:11:37.440', 'end': '00:11:41.630', 'text': \"the model. So we've talked about now rag\\nas being one option and we talked about\"}, {'start': '00:11:41.630', 'end': '00:11:41.640', 'text': 'as being one option and we talked about'}, {'start': '00:11:41.640', 'end': '00:11:45.590', 'text': 'as being one option and we talked about\\nfine tuning as being another one and now'}, {'start': '00:11:45.590', 'end': '00:11:45.600', 'text': 'fine tuning as being another one and now'}, {'start': '00:11:45.600', 'end': '00:11:49.230', 'text': \"fine tuning as being another one and now\\njust now we've talked about prompt\"}, {'start': '00:11:49.230', 'end': '00:11:49.240', 'text': \"just now we've talked about prompt\"}, {'start': '00:11:49.240', 'end': '00:11:51.990', 'text': \"just now we've talked about prompt\\nengineering as well and I've really\"}, {'start': '00:11:51.990', 'end': '00:11:52.000', 'text': \"engineering as well and I've really\"}, {'start': '00:11:52.000', 'end': '00:11:55.710', 'text': \"engineering as well and I've really\\ntalked about those as three different\"}, {'start': '00:11:55.710', 'end': '00:11:55.720', 'text': 'talked about those as three different'}, {'start': '00:11:55.720', 'end': '00:11:58.790', 'text': \"talked about those as three different\\ndistinct things here but they're\"}, {'start': '00:11:58.790', 'end': '00:11:58.800', 'text': \"distinct things here but they're\"}, {'start': '00:11:58.800', 'end': '00:12:02.310', 'text': \"distinct things here but they're\\ncommonly used actually in combination.\"}, {'start': '00:12:02.310', 'end': '00:12:02.320', 'text': 'commonly used actually in combination.'}, {'start': '00:12:02.320', 'end': '00:12:05.509', 'text': 'commonly used actually in combination.\\nWe might use all three together. So'}, {'start': '00:12:05.509', 'end': '00:12:05.519', 'text': 'We might use all three together. So'}, {'start': '00:12:05.519', 'end': '00:12:08.629', 'text': 'We might use all three together. So\\nconsider a legal AI system. Rag that'}, {'start': '00:12:08.629', 'end': '00:12:08.639', 'text': 'consider a legal AI system. Rag that'}, {'start': '00:12:08.639', 'end': '00:12:11.509', 'text': 'consider a legal AI system. Rag that\\ncould retrieve specific cases and recent'}, {'start': '00:12:11.509', 'end': '00:12:11.519', 'text': 'could retrieve specific cases and recent'}, {'start': '00:12:11.519', 'end': '00:12:13.990', 'text': 'could retrieve specific cases and recent\\ncourt decisions. Uh the prompt'}, {'start': '00:12:13.990', 'end': '00:12:14.000', 'text': 'court decisions. Uh the prompt'}, {'start': '00:12:14.000', 'end': '00:12:15.670', 'text': 'court decisions. Uh the prompt\\nengineering part that could make sure'}, {'start': '00:12:15.670', 'end': '00:12:15.680', 'text': 'engineering part that could make sure'}, {'start': '00:12:15.680', 'end': '00:12:17.509', 'text': 'engineering part that could make sure\\nthat we follow proper legal document'}, {'start': '00:12:17.509', 'end': '00:12:17.519', 'text': 'that we follow proper legal document'}, {'start': '00:12:17.519', 'end': '00:12:19.990', 'text': 'that we follow proper legal document\\nformats by asking for it. And then'}, {'start': '00:12:19.990', 'end': '00:12:20.000', 'text': 'formats by asking for it. And then'}, {'start': '00:12:20.000', 'end': '00:12:21.509', 'text': 'formats by asking for it. And then\\nfine-tuning that could help the model'}, {'start': '00:12:21.509', 'end': '00:12:21.519', 'text': 'fine-tuning that could help the model'}, {'start': '00:12:21.519', 'end': '00:12:24.790', 'text': 'fine-tuning that could help the model\\nmaster firm specific policies. I mean'}, {'start': '00:12:24.790', 'end': '00:12:24.800', 'text': 'master firm specific policies. I mean'}, {'start': '00:12:24.800', 'end': '00:12:27.030', 'text': 'master firm specific policies. I mean\\nbasically we can think of it like this.'}, {'start': '00:12:27.030', 'end': '00:12:27.040', 'text': 'basically we can think of it like this.'}, {'start': '00:12:27.040', 'end': '00:12:29.030', 'text': 'basically we can think of it like this.\\nWe can think that prompt engineering'}, {'start': '00:12:29.030', 'end': '00:12:29.040', 'text': 'We can think that prompt engineering'}, {'start': '00:12:29.040', 'end': '00:12:32.150', 'text': 'We can think that prompt engineering\\noffers flexibility and immediate results'}, {'start': '00:12:32.150', 'end': '00:12:32.160', 'text': 'offers flexibility and immediate results'}, {'start': '00:12:32.160', 'end': '00:12:34.949', 'text': \"offers flexibility and immediate results\\nbut it can't extend knowledge. Rag that\"}, {'start': '00:12:34.949', 'end': '00:12:34.959', 'text': \"but it can't extend knowledge. Rag that\"}, {'start': '00:12:34.959', 'end': '00:12:36.389', 'text': \"but it can't extend knowledge. Rag that\\ncan extend knowledge. It provides\"}, {'start': '00:12:36.389', 'end': '00:12:36.399', 'text': 'can extend knowledge. It provides'}, {'start': '00:12:36.399', 'end': '00:12:38.550', 'text': 'can extend knowledge. It provides\\nupto-date information but with'}, {'start': '00:12:38.550', 'end': '00:12:38.560', 'text': 'upto-date information but with'}, {'start': '00:12:38.560', 'end': '00:12:40.509', 'text': 'upto-date information but with\\ncomputational overhead and then'}, {'start': '00:12:40.509', 'end': '00:12:40.519', 'text': 'computational overhead and then'}, {'start': '00:12:40.519', 'end': '00:12:43.269', 'text': 'computational overhead and then\\nfine-tuning that enables deep domain'}, {'start': '00:12:43.269', 'end': '00:12:43.279', 'text': 'fine-tuning that enables deep domain'}, {'start': '00:12:43.279', 'end': '00:12:45.590', 'text': 'fine-tuning that enables deep domain\\nexpertise but it requires significant'}, {'start': '00:12:45.590', 'end': '00:12:45.600', 'text': 'expertise but it requires significant'}, {'start': '00:12:45.600', 'end': '00:12:48.310', 'text': 'expertise but it requires significant\\nresources and maintenance. Basically it'}, {'start': '00:12:48.310', 'end': '00:12:48.320', 'text': 'resources and maintenance. Basically it'}, {'start': '00:12:48.320', 'end': '00:12:51.030', 'text': 'resources and maintenance. Basically it\\ncomes down to picking the methods that'}, {'start': '00:12:51.030', 'end': '00:12:51.040', 'text': 'comes down to picking the methods that'}, {'start': '00:12:51.040', 'end': '00:12:54.629', 'text': \"comes down to picking the methods that\\nwork for you. You know, we've we sure\"}, {'start': '00:12:54.629', 'end': '00:12:54.639', 'text': \"work for you. You know, we've we sure\"}, {'start': '00:12:54.639', 'end': '00:12:57.350', 'text': \"work for you. You know, we've we sure\\ncome a long way from vanity searching on\"}, {'start': '00:12:57.350', 'end': '00:12:57.360', 'text': 'come a long way from vanity searching on'}, {'start': '00:12:57.360', 'end': '00:13:00.360', 'text': 'come a long way from vanity searching on\\nGoogle'}]\n",
      "üíæ Saving transcript files...\n",
      "‚úÖ Saved: 'transcript.txt' and 'transcript.json'\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "import webvtt\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "VIDEO_URL = \"https://www.youtube.com/watch?v=zYGDpG-pTho&t=456s\"\n",
    "VTT_FILENAME = \"transcript_temp.en.vtt\"\n",
    "TXT_OUTPUT = \"transcript.txt\"\n",
    "JSON_OUTPUT = \"transcript.json\"\n",
    "\n",
    "\n",
    "def download_subtitles(video_url: str, vtt_filename: str):\n",
    "    options = {\n",
    "        'skip_download': True,\n",
    "        'writesubtitles': False,\n",
    "        'writeautomaticsub': True,\n",
    "        'subtitleslangs': ['en'],\n",
    "        'subtitlesformat': 'vtt',\n",
    "        'outtmpl': 'transcript_temp.%(ext)s',\n",
    "        'noplaylist': True\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(options) as ydl:\n",
    "        ydl.download([video_url])\n",
    "\n",
    "\n",
    "def parse_and_clean_vtt(vtt_filename: str):\n",
    "    transcript_list = []\n",
    "    transcript_text = \"\"\n",
    "\n",
    "    for caption in webvtt.read(vtt_filename):\n",
    "        line = caption.text.strip()\n",
    "        transcript_list.append({\n",
    "            \"start\": caption.start,\n",
    "            \"end\": caption.end,\n",
    "            \"text\": line\n",
    "        })\n",
    "        transcript_text += line + \"\\n\"\n",
    "\n",
    "    lines = transcript_text.strip().splitlines()\n",
    "\n",
    "    # Remove consecutive duplicates\n",
    "    cleaned_lines = []\n",
    "    previous_line = None\n",
    "    for line in lines:\n",
    "        if line != previous_line:\n",
    "            cleaned_lines.append(line)\n",
    "        previous_line = line\n",
    "\n",
    "    cleaned_text = \"\\n\".join(cleaned_lines)\n",
    "    print(cleaned_text)\n",
    "    print('\\n')\n",
    "    print(transcript_list)\n",
    "    return cleaned_text, transcript_list\n",
    "\n",
    "\n",
    "def save_transcript(txt_path: str, json_path: str, text: str, metadata: list):\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as txt_out:\n",
    "        txt_out.write(text)\n",
    "\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as json_out:\n",
    "        json.dump(metadata, json_out, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"üì• Downloading subtitles...\")\n",
    "    download_subtitles(VIDEO_URL, VTT_FILENAME)\n",
    "\n",
    "    if os.path.exists(VTT_FILENAME):\n",
    "        print(\"üìÑ Processing subtitle file...\")\n",
    "        cleaned_text, transcript_data = parse_and_clean_vtt(VTT_FILENAME)\n",
    "\n",
    "        print(\"üíæ Saving transcript files...\")\n",
    "        save_transcript(TXT_OUTPUT, JSON_OUTPUT, cleaned_text, transcript_data)\n",
    "\n",
    "        print(f\"‚úÖ Saved: '{TXT_OUTPUT}' and '{JSON_OUTPUT}'\")\n",
    "    else:\n",
    "        print(\"‚ùå Subtitle file not found.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5982763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
