{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9429759f",
   "metadata": {},
   "source": [
    "### Import Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f1b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "from pprint import pprint\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e342ce75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEstimate Usage of Your Script\\nYou extract metadata (1 unit)\\nYou extract 200 comments (3 units)\\nEach run = ~4 quota units\\nðŸ” You can run this script ~2,500 times/day using your default 10,000 unit quota.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Estimate Usage of Your Script\n",
    "You extract metadata (1 unit)\n",
    "You extract 200 comments (3 units)\n",
    "Each run = ~4 quota units\n",
    "ðŸ” You can run this script ~2,500 times/day using your default 10,000 unit quota.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb140c4",
   "metadata": {},
   "source": [
    "### Connect with YouTube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b998f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Extracted Video ID: z-moiQlcC6c\n"
     ]
    }
   ],
   "source": [
    "def extract_youtube_video_id(url: str) -> str:\n",
    "    pattern = r\"(?:v=|\\/)([0-9A-Za-z_-]{11})(?:[\\?&\\/]|$)\"\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Example usage\n",
    "yt_url = \"https://www.youtube.com/watch?v=z-moiQlcC6c&list=PLv8Cp2NvcY8AzNCATbDWMr8vqbJBYbxFW&index=8\"\n",
    "video_id = extract_youtube_video_id(yt_url)\n",
    "print(\"ðŸŽ¯ Extracted Video ID:\", video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b46010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<googleapiclient.discovery.Resource object at 0x00000215F18C4EB0>\n"
     ]
    }
   ],
   "source": [
    "# Your YouTube API key\n",
    "API_KEY = \"\"\n",
    "VIDEO_ID = video_id\n",
    "MAX_COMMENTS = 20  # Adjust this as needed (pagination will handle it)\n",
    "\n",
    "# Connect to YouTube API\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "print(youtube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49864783",
   "metadata": {},
   "source": [
    "### Extract Video Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e49944c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': 'z-moiQlcC6c',\n",
       " 'title': 'L-4 Step-by-Step Guide to Building a ChatGPT Clone',\n",
       " 'description': \"In this step-by-step guide, I'll show you how to build your own ChatGPT clone using LangChain, OpenAI API, and Streamlit. Whether you're a beginner or an experienced developer, this video will walk you through the entire process, from setting up your environment to deploying your chatbot.\\n\\nCode Repository:\\nCheck out the code on GitHub:  https://github.com/AarohiSingla/Generative_AI/tree/main/L-4/chatgpt_clone\\n\\nDon't forget to like, comment, and subscribe for more tutorials! If you have any questions or run into issues, feel free to leave a comment below. Happy coding!\\n\\n\\nIn this video, you'll learn:\\n\\nHow to set up and configure LangChain.\\nHow to integrate the OpenAI API for chatbot functionalities.\\nHow to use Streamlit to create a user-friendly interface.\\n\\n#chatgpt #llms #generativeai #openai #openaiapi #languagemodels #langchain #gpt #gpt3\",\n",
       " 'published_at': '2024-07-17T01:52:23Z',\n",
       " 'channel_title': 'Code With Aarohi',\n",
       " 'tags': ['openaiapi',\n",
       "  'openai',\n",
       "  'chatgpt',\n",
       "  'llms',\n",
       "  'generativeai',\n",
       "  'langchain',\n",
       "  'gpt',\n",
       "  'gpt3'],\n",
       " 'view_count': 3954,\n",
       " 'like_count': 79,\n",
       " 'comment_count': 32}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_video_metadata(video_id):\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet,statistics\",\n",
    "        id=video_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    video = response[\"items\"][0]\n",
    "\n",
    "    metadata = {\n",
    "        \"video_id\": video_id,\n",
    "        \"title\": video[\"snippet\"][\"title\"],\n",
    "        \"description\": video[\"snippet\"][\"description\"],\n",
    "        \"published_at\": video[\"snippet\"][\"publishedAt\"],\n",
    "        \"channel_title\": video[\"snippet\"][\"channelTitle\"],\n",
    "        \"tags\": video[\"snippet\"].get(\"tags\", []),\n",
    "        \"view_count\": int(video[\"statistics\"].get(\"viewCount\", 0)),\n",
    "        \"like_count\": int(video[\"statistics\"].get(\"likeCount\", 0)),\n",
    "        \"comment_count\": int(video[\"statistics\"].get(\"commentCount\", 0))\n",
    "    }\n",
    "\n",
    "    return metadata\n",
    "\n",
    "get_video_metadata(VIDEO_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1afce",
   "metadata": {},
   "source": [
    "### Extract Top Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_comments(video_id, max_comments=100):\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(comments) < max_comments:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=min(100, max_comments - len(comments)),\n",
    "            pageToken=next_page_token,\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response[\"items\"]:\n",
    "            comment_info = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            comments.append({\n",
    "                \"author\": comment_info[\"authorDisplayName\"],\n",
    "                \"text\": comment_info[\"textDisplay\"],\n",
    "                \"like_count\": comment_info[\"likeCount\"],\n",
    "                \"published_at\": comment_info[\"publishedAt\"],\n",
    "                \"updated_at\": comment_info.get(\"updatedAt\"),\n",
    "            })\n",
    "\n",
    "        next_page_token = response.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return comments\n",
    "\n",
    "get_video_comments(VIDEO_ID, MAX_COMMENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa69d5",
   "metadata": {},
   "source": [
    "### Save Comments & Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a22bd03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ Create structured folders for saving data\n",
    "BASE_DIR = \"youtube_data\"\n",
    "COMMENTS_DIR = os.path.join(BASE_DIR, \"comments\")\n",
    "METADATA_DIR = os.path.join(BASE_DIR, \"metadata\")\n",
    "\n",
    "# âœ… Create directories if they don't exist\n",
    "os.makedirs(COMMENTS_DIR, exist_ok=True)\n",
    "os.makedirs(METADATA_DIR, exist_ok=True)\n",
    "\n",
    "def save_comments_to_txt(comments, filename=\"comments.txt\"):\n",
    "    filepath = os.path.join(COMMENTS_DIR, filename)\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, c in enumerate(comments, start=1):\n",
    "            f.write(f\"{i}. {c['text']}\\n\")\n",
    "\n",
    "def save_comments_to_csv(comments, filename=\"comments.csv\"):\n",
    "    filepath = os.path.join(COMMENTS_DIR, filename)\n",
    "    with open(filepath, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=comments[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(comments)\n",
    "\n",
    "def save_metadata_to_json(metadata, filename=\"video_metadata.json\"):\n",
    "    filepath = os.path.join(METADATA_DIR, filename)\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8614ac9",
   "metadata": {},
   "source": [
    "### Testing Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e8812e",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 503 when requesting https://youtube.googleapis.com/youtube/v3/videos?part=snippet%2Cstatistics&id=z-moiQlcC6c&key=AIzaSyC_5u5qYLvHXHEU2q0giodGwzZ6V8ogqBQ&alt=json returned \"Visibility check was unavailable. Please retry the request and contact support if the problem persists\". Details: \"[{'message': 'Visibility check was unavailable. Please retry the request and contact support if the problem persists', 'domain': 'global', 'reason': 'backendError'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m video_meta \u001b[38;5;241m=\u001b[39m \u001b[43mget_video_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVIDEO_ID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m comments \u001b[38;5;241m=\u001b[39m get_video_comments(VIDEO_ID, max_comments\u001b[38;5;241m=\u001b[39mMAX_COMMENTS)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ“½ï¸ Video Title: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mget_video_metadata\u001b[1;34m(video_id)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_video_metadata\u001b[39m(video_id):\n\u001b[0;32m      2\u001b[0m     request \u001b[38;5;241m=\u001b[39m youtube\u001b[38;5;241m.\u001b[39mvideos()\u001b[38;5;241m.\u001b[39mlist(\n\u001b[0;32m      3\u001b[0m         part\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnippet,statistics\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mvideo_id\n\u001b[0;32m      5\u001b[0m     )\n\u001b[1;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     video \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: video_id,\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnippet\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatistics\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommentCount\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     19\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\YT_Video_Summariser\\venv\\lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\YT_Video_Summariser\\venv\\lib\\site-packages\\googleapiclient\\http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    936\u001b[0m     callback(resp)\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 503 when requesting https://youtube.googleapis.com/youtube/v3/videos?part=snippet%2Cstatistics&id=z-moiQlcC6c&key=AIzaSyC_5u5qYLvHXHEU2q0giodGwzZ6V8ogqBQ&alt=json returned \"Visibility check was unavailable. Please retry the request and contact support if the problem persists\". Details: \"[{'message': 'Visibility check was unavailable. Please retry the request and contact support if the problem persists', 'domain': 'global', 'reason': 'backendError'}]\">"
     ]
    }
   ],
   "source": [
    "video_meta = get_video_metadata(VIDEO_ID)\n",
    "comments = get_video_comments(VIDEO_ID, max_comments=MAX_COMMENTS)\n",
    "\n",
    "print(f\"\\nðŸ“½ï¸ Video Title: {video_meta['title']}\")\n",
    "print(f\"ðŸ’¬ Total Comments Extracted: {len(comments)}\\n\")\n",
    "\n",
    "# Optional preview\n",
    "for i, c in enumerate(comments[:5], start=1):\n",
    "    print(f\"{i}. {c['text']}\")\n",
    "\n",
    "# Save outputs\n",
    "save_metadata_to_json(video_meta)\n",
    "save_comments_to_txt(comments)\n",
    "save_comments_to_csv(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446321d6",
   "metadata": {},
   "source": [
    "### Setup Google API & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7215567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am doing well, thank you for asking!  How are you today?\n",
      "{'input_tokens': 6, 'output_tokens': 17, 'total_tokens': 23, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Set up your API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBdEvwL5VxpxQtDX5Nd4DsuNJRmSNjFne0\"\n",
    "\n",
    "# Set up Google Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.5, max_tokens=500)\n",
    "response = llm.invoke(\"Hi, How are you?\")\n",
    "print(response.content)\n",
    "print(response.usage_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fc69332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Video Metadata: {'video_id': 'z-moiQlcC6c', 'title': 'L-4 Step-by-Step Guide \"\n",
      " 'to Building a ChatGPT Clone\\', \\'description\\': \"In this step-by-step guide, '\n",
      " \"I'll show you how to build your own ChatGPT clone using LangChain, OpenAI \"\n",
      " \"API, and Streamlit. Whether you're a beginner or an experienced developer, \"\n",
      " 'this video will walk you through the entire process, from setting up your '\n",
      " 'environment to deploying your chatbot.\\\\n\\\\nCode Repository:\\\\nCheck out the '\n",
      " 'code on GitHub:  '\n",
      " \"https://github.com/AarohiSingla/Generative_AI/tree/main/L-4/chatgpt_clone\\\\n\\\\nDon't \"\n",
      " 'forget to like, comment, and subscribe for more tutorials! If you have any '\n",
      " 'questions or run into issues, feel free to leave a comment below. Happy '\n",
      " \"coding!\\\\n\\\\n\\\\nIn this video, you'll learn:\\\\n\\\\nHow to set up and \"\n",
      " 'configure LangChain.\\\\nHow to integrate the OpenAI API for chatbot '\n",
      " 'functionalities.\\\\nHow to use Streamlit to create a user-friendly '\n",
      " 'interface.\\\\n\\\\n#chatgpt #llms #generativeai #openai #openaiapi '\n",
      " '#languagemodels #langchain #gpt #gpt3\", \\'published_at\\': '\n",
      " \"'2024-07-17T01:52:23Z', 'channel_title': 'Code With Aarohi', 'tags': \"\n",
      " \"['openaiapi', 'openai', 'chatgpt', 'llms', 'generativeai', 'langchain', \"\n",
      " \"'gpt', 'gpt3'], 'view_count': 3954, 'like_count': 79, 'comment_count': 32}\")\n",
      "(\"Comments: [{'author': '@danielvoss2483', 'text': 'Nice work, Thanks', \"\n",
      " \"'like_count': 0, 'published_at': '2025-06-06T06:48:06Z', 'updated_at': \"\n",
      " \"'2025-06-06T06:48:06Z'}, {'author': '@THEINDIANSAVIOR', 'text': 'Hello mam, \"\n",
      " 'this is an amazing project that even I built from scratch, which means a '\n",
      " \"lot. I explained this in my college presentation. ðŸ˜‡ðŸ˜‡ðŸ‘ðŸ‘ðŸ¤›â¤', 'like_count': 0, \"\n",
      " \"'published_at': '2025-02-19T00:49:06Z', 'updated_at': \"\n",
      " \"'2025-02-19T00:49:06Z'}, {'author': '@lipaacharjee9083', 'text': 'Mam, after \"\n",
      " 'completing the Playlist of Gen AI, what all project we can build, some idea, '\n",
      " 'I mean if you can make a video on roadmap for Gen AI regarding projects and '\n",
      " 'all, that would be helpful as well. I mean how can we land with a job? '\n",
      " \"Regards', 'like_count': 0, 'published_at': '2025-01-23T06:03:26Z', \"\n",
      " \"'updated_at': '2025-01-23T06:03:26Z'}, {'author': '@sangeethag8228', 'text': \"\n",
      " \"'Thank you so much for the great and simple explanation, Mam.  Simply great \"\n",
      " \"with the latest trends . God Bless you', 'like_count': 0, 'published_at': \"\n",
      " \"'2024-11-06T14:34:51Z', 'updated_at': '2024-11-06T14:34:51Z'}, {'author': \"\n",
      " \"'@alexramos587', 'text': 'Good content.', 'like_count': 0, 'published_at': \"\n",
      " \"'2024-10-16T09:15:55Z', 'updated_at': '2024-10-16T09:15:55Z'}, {'author': \"\n",
      " \"'@soravsingla8782', 'text': 'Your videos are exceptional', 'like_count': 0, \"\n",
      " \"'published_at': '2024-09-30T10:03:22Z', 'updated_at': \"\n",
      " '\\'2024-09-30T10:03:22Z\\'}, {\\'author\\': \\'@Ritesh_1804\\', \\'text\\': \"Ma\\'am, '\n",
      " 'in your application, you are simply appending the user message and the '\n",
      " 'response from the model to the session state. During the next user input, we '\n",
      " 'pass this to the model to maintain the context window. But what if we have a '\n",
      " 'long conversation? How can we pass all the messages to the model? Will it '\n",
      " 'give an error as we will exceed the token limit (context window of the LLM)? '\n",
      " 'Please explain.\\\\n\\\\nbtw Thanks ma\\'am your explanation is supeerrrbbb :)\", '\n",
      " \"'like_count': 0, 'published_at': '2024-09-05T12:10:15Z', 'updated_at': \"\n",
      " \"'2024-09-05T12:11:20Z'}, {'author': '@arnavthakur5409', 'text': 'Very \"\n",
      " \"impressive video maam', 'like_count': 1, 'published_at': \"\n",
      " \"'2024-09-05T09:16:37Z', 'updated_at': '2024-09-05T09:16:37Z'}, {'author': \"\n",
      " \"'@AkulSamartha', 'text': 'One more video, packed with all the information, \"\n",
      " \"explained in simple terms. ðŸ‘', 'like_count': 0, 'published_at': \"\n",
      " \"'2024-08-07T07:32:04Z', 'updated_at': '2024-08-07T07:32:04Z'}, {'author': \"\n",
      " \"'@Umairkhan-j8p', 'text': 'Mam Please make video on Fine tunning  and make \"\n",
      " \"one end to project on fine tunning please', 'like_count': 0, 'published_at': \"\n",
      " \"'2024-07-22T07:23:59Z', 'updated_at': '2024-07-22T07:23:59Z'}]\")\n"
     ]
    }
   ],
   "source": [
    "video_metadata = get_video_metadata(VIDEO_ID)\n",
    "comments = get_video_comments(VIDEO_ID, max_comments=MAX_COMMENTS)\n",
    "\n",
    "pprint(f\"Video Metadata: {video_metadata}\")\n",
    "pprint(f\"Comments: {comments[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "229b7abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello mam, this is an amazing project that even I built from scratch, which means a lot. I explained this in my college presentation. ðŸ˜‡ðŸ˜‡ðŸ‘ðŸ‘ðŸ¤›â¤ Mam, after completing the Playlist of Gen AI, what all project we can build, some idea, I mean if you can make a video on roadmap for Gen AI regarding projects and all, that would be helpful as well. I mean how can we land with a job? Regards Thank you so much for the great and simple explanation, Mam.  Simply great with the latest trends . God Bless you Good content. Your videos are exceptional Ma'am, in your application, you are simply appending the user message and the response from the model to the session state. During the next user input, we pass this to the model to maintain the context window. But what if we have a long conversation? How can we pass all the messages to the model? Will it give an error as we will exceed the token limit (context window of the LLM)? Please explain.\n",
      "\n",
      "btw Thanks ma'am your explanation is supeerrrbbb :) Very impressive video maam One more video, packed with all the information, explained in simple terms. ðŸ‘ Mam Please make video on Fine tunning  and make one end to project on fine tunning please Thank you for this tutorial! Mam, please make videos on rag and fine tunning Can you share deployment also. I'm trying to deploy on streamlit but some cuda issues and error We can not thank you more than praying for you madam , God Almighty will continue blessing you the great job you are rendering through this your YouTube channel\n"
     ]
    }
   ],
   "source": [
    "comment_list = [comment['text'] for comment in comments]\n",
    "# pprint(comment_list[1:])\n",
    "\n",
    "all_comments = ' '.join(comment_list[1:])\n",
    "print(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11fb7fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[Document(metadata={}, page_content=\"Hello mam, this is an amazing project that even I built from scratch, which means a lot. I explained this in my college presentation. ðŸ˜‡ðŸ˜‡ðŸ‘ðŸ‘ðŸ¤›â¤ Mam, after completing the Playlist of Gen AI, what all project we can build, some idea, I mean if you can make a video on roadmap for Gen AI regarding projects and all, that would be helpful as well. I mean how can we land with a job? Regards Thank you so much for the great and simple explanation, Mam.  Simply great with the latest trends . God Bless you Good content. Your videos are exceptional Ma'am, in your application, you are simply appending the user message and the response from the model to the session state. During the next user input, we pass this to the model to maintain the context window. But what if we have a long conversation? How can we pass all the messages to the model? Will it give an error as we will exceed the token limit (context window of the LLM)? Please explain.\"),\n",
      " Document(metadata={}, page_content=\"btw Thanks ma'am your explanation is supeerrrbbb :) Very impressive video maam One more video, packed with all the information, explained in simple terms. ðŸ‘ Mam Please make video on Fine tunning  and make one end to project on fine tunning please Thank you for this tutorial! Mam, please make videos on rag and fine tunning Can you share deployment also. I'm trying to deploy on streamlit but some cuda issues and error We can not thank you more than praying for you madam , God Almighty will continue blessing you the great job you are rendering through this your YouTube channel\")]\n"
     ]
    }
   ],
   "source": [
    "# Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=500)\n",
    "chunks = text_splitter.create_documents([all_comments])\n",
    "\n",
    "# Check number of chunks\n",
    "pprint(len(chunks))\n",
    "pprint(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eb2c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define final combine prompt template\n",
    "final_combine_prompt = '''\n",
    "You are aggregating summaries of YouTube video comments.\n",
    "Based on the following partial summaries from different chunks of comments, provide a **concise, clear final summary** of what people are saying overall.\n",
    "Highlight:\n",
    "- Common sentiments\n",
    "- Frequently discussed topics\n",
    "- Any polarizing opinions or praise/criticism\n",
    "Summaries:\n",
    "{text}\n",
    "Final Summary:\n",
    "'''\n",
    "final_combine_prompt_template = PromptTemplate(input_variables=['text'], template=final_combine_prompt)\n",
    "\n",
    "\n",
    "# Define summarization prompt template\n",
    "chunks_prompt = '''\n",
    "You are analyzing YouTube video comments. Summarize the **main points, opinions, or recurring themes** mentioned in the following user comments.\n",
    "Make the summary concise and use bullet points if helpful.\n",
    "Comments:\n",
    "{text}\n",
    "'''\n",
    "map_prompt_template = PromptTemplate(input_variables=['text'], template=chunks_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5aeb4dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m summary_chain\u001b[38;5;241m.\u001b[39minvoke(chunks)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Print the final summary\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m pprint(\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Load summarize chain with map-reduce strategy\n",
    "summary_chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='map_reduce',\n",
    "    map_prompt=map_prompt_template,\n",
    "    combine_prompt=final_combine_prompt_template,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Run summarization on text chunks\n",
    "output = summary_chain.invoke(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f1056be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Viewers overwhelmingly praise the video's quality and the instructor's clear \"\n",
      " 'teaching style.  Common requests include future videos on fine-tuning, RAG, '\n",
      " 'and Streamlit deployment, as well as a video offering Gen AI project ideas '\n",
      " 'and career advice.  A technical concern regarding context window limitations '\n",
      " 'in long conversations with LLMs was also raised.')\n"
     ]
    }
   ],
   "source": [
    "# Print the final summary\n",
    "pprint(output['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3debc5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata:\n",
      "title: L-4 Step-by-Step Guide to Building a ChatGPT Clone\n",
      "published_at: 2024-07-17T01:52:23Z\n",
      "channel_title: Code With Aarohi\n",
      "view_count: 3911\n",
      "like_count: 78\n",
      "comment_count: 31\n"
     ]
    }
   ],
   "source": [
    "print(\"Metadata:\")\n",
    "for keys, values in video_metadata.items():\n",
    "    if keys in ['title', 'channel_title', 'published_at', 'view_count', 'like_count', 'comment_count'] :\n",
    "        print(f\"{keys}: {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a6e9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
